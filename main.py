"""
ìŒì•… ì´ë¡  RAG ì‹œìŠ¤í…œ ì „ì²´ ê°ì²´ ì´ˆê¸°í™” ë° (ìˆ˜ë™/ìë™/ë°°ì¹˜) ì§„ì…ì 
"""

import os
from src.data_processing.json_loader import MusicTheoryDataLoader
from src.data_processing.embedding_generator import EmbeddingGenerator
from src.models.retriever import VectorRetriever
from src.models.rag_model import RAGModel

def initialize_system(force_regenerate: bool = False):
    print("ğŸµ ìŒì•… ì´ë¡  RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")

    # 1. ë°ì´í„° ë¡œë“œ
    loader = MusicTheoryDataLoader()
    data = loader.load_data()
    if not data:
        raise RuntimeError("ìŒì•…ì´ë¡  ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨!")

    # 2. ì„ë² ë”© ì²˜ë¦¬
    embedder = EmbeddingGenerator()
    embedding_dir = 'data/embeddings'
    embedding_path = os.path.join(embedding_dir, 'music_theory_embeddings.pkl')
    json_path = 'data/raw/music_theory_curriculum.json'

    need_regen = force_regenerate
    if os.path.exists(embedding_path) and os.path.exists(json_path):
        if os.path.getmtime(json_path) > os.path.getmtime(embedding_path):
            need_regen = True
    if need_regen or not embedder.load_embeddings():
        print("   ğŸ”„ ì„ë² ë”© ìƒì„± ì‹œì‘...")
        chunks = loader.extract_text_chunks()
        embedder.generate_embeddings(chunks)
        embedder.save_embeddings()
        print("   âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ!")
    else:
        print("   âœ… ì„ë² ë”© ë¡œë“œ ì™„ë£Œ!")

    # 3. ê²€ìƒ‰ê¸°(ë²¡í„°) ì´ˆê¸°í™”
    retriever = VectorRetriever()
    if not retriever.load_embeddings():
        raise RuntimeError("ê²€ìƒ‰ê¸° ì„ë² ë”© ë¡œë“œ ì‹¤íŒ¨!")
    if not retriever.build_index():
        raise RuntimeError("ê²€ìƒ‰ê¸° ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨!")

    # 4. RAG ëª¨ë¸ ë˜í¼ ì´ˆê¸°í™”
    rag_model = RAGModel(retriever)
    print("âœ… RAG ì‹œìŠ¤í…œ ê°ì²´ ìƒì„± ì„±ê³µ!")
    return rag_model

def cli_launcher():
    """ (ì„ íƒ) CLI/manual í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸° """
    rag_model = initialize_system()
    print("\nğŸŒ± (ìŒì•… ì´ë¡  RAG) ììœ  ì…ë ¥ CLI ëª¨ë“œì…ë‹ˆë‹¤. ì¢…ë£Œ: exit/quit ì…ë ¥\n")
    try:
        while True:
            query = input("\nì§ˆë¬¸(ì¢…ë£Œ: exit): ")
            if query.strip().lower() in ["exit", "quit"]:
                print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            # ì‹¤ì œ rag_model/retriever_inner ë™ì‘ ë¡œê·¸ ë³´ê¸°!
            response = rag_model.get_conversation_response(query)
            topk_sources = response.get("sources", [])
            print("\n[ë‹µë³€]")
            print(response.get('answer', ''))
            print("\n[ì°¸ê³  passage ê°œìˆ˜]:", len(topk_sources))

            # # === ğŸ” ìƒì„¸ Top-K candidate ë¡œê·¸ í™•ì¸ ===
            # if topk_sources:
            #     print(f"\n==== [ê²€ìƒ‰ Top-K í›„ë³´ ìƒì„¸] ====")
            #     for idx, p in enumerate(topk_sources):
            #         print(f"{idx+1}. {p.get('concept.ko', p.get('concept.en'))} | node_id={p.get('node_id')} | type={p.get('concept_type')} | score={p.get('score',0):.3f} | rank={p.get('rank')}")

            # else:
            #     print("â€» Top-K passageê°€ ì—†ìŒ! (ê²€ìƒ‰ miss)")
    except Exception as e:
        print("\n[ì˜¤ë¥˜] ì‹¤í–‰ ì¤‘ ì—ëŸ¬ ë°œìƒ:", e)
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # CLI/manual interactive í…ŒìŠ¤íŠ¸ ëª¨ë“œ
    cli_launcher()

    # ìë™í‰ê°€/ì‹¤í—˜ì„ ìœ„í•´ì„œëŠ” ì´ íŒŒì¼ì´ ì•„ë‹ˆë¼ run_experiment.py ë“± (src/experiments/...)ì—ì„œ
    # from main import initialize_system
    # rag_model = initialize_system()  # importí•´ì„œ ì‚¬ìš©!
import numpy as np
import faiss
from typing import List, Dict, Tuple
import pickle
import os
from sentence_transformers import SentenceTransformer

class VectorRetriever:
    def __init__(
        self, 
        embedding_path: str = 'data/embeddings/music_theory_embeddings.pkl',
        metadata_file: str = 'data/embeddings/embeddings_metadata.json',
        index_path: str = 'data/embeddings/faiss_index.idx'
    ):
        """ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰ê¸° ì´ˆê¸°í™”"""
        print(f"   ğŸ”§ VectorRetriever ì´ˆê¸°í™” ì‹œì‘")
        print(f"   - embedding_path: {embedding_path}")
        print(f"   - index_path: {index_path}")
        
        # ê²½ë¡œ ì„¤ì •
        self.embedding_path = embedding_path
        self.index_path = index_path
        
        # ì†ì„± ì´ˆê¸°í™”
        self.embeddings = None
        self.chunks = None
        self.index = None
        self.model = None
        self.model_name = None
        
        print(f"   âœ… VectorRetriever ì´ˆê¸°í™” ì™„ë£Œ")
        # print(f"   - self: {self}")
    
    def load_embeddings(self):
        """ì €ì¥ëœ ì„ë² ë”© ë¡œë“œ"""
        try:
            # ì„ë² ë”© íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(self.embedding_path):
                print(f"âŒ ì„ë² ë”© íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.embedding_path}")
                return False
            
            # ì„ë² ë”© ë¡œë“œ
            with open(self.embedding_path, 'rb') as f:
                embedding_data = pickle.load(f)
            
            # ì†ì„± ì„¤ì •
            self.embeddings = np.array(embedding_data['embeddings'])
            self.chunks = embedding_data['chunks']
            self.model_name = embedding_data.get('model_name', 'unknown')
            
            # ëª¨ë¸ ë¡œë“œ (ê²€ìƒ‰ ì‹œ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±ìš©)
            self.model = SentenceTransformer(self.model_name)
            
            print(f"âœ… ì„ë² ë”© ë¡œë“œ ì™„ë£Œ: {len(self.chunks)}ê°œ ì²­í¬, ëª¨ë¸: {self.model_name}")
            return True
        
        except Exception as e:
            print(f"âŒ ì„ë² ë”© ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def build_index(self, embeddings=None, chunks=None):
        """
        FAISS ì¸ë±ìŠ¤ êµ¬ì¶•
        
        :param embeddings: ì„ íƒì  ì„ë² ë”© ë°°ì—´
        :param chunks: ì„ íƒì  ì²­í¬ ë°ì´í„°
        """
        print("ğŸ”§ build_index í˜¸ì¶œë¨")
        
        # ì¸ìë¡œ ì „ë‹¬ëœ ì„ë² ë”©/ì²­í¬ ì‚¬ìš©
        if embeddings is not None:
            print(f"   - ìƒˆ ì„ë² ë”© ì „ë‹¬ë¨: {type(embeddings)}")
            self.embeddings = embeddings
        if chunks is not None:
            print(f"   - ìƒˆ ì²­í¬ ì „ë‹¬ë¨: {len(chunks)}ê°œ")
            self.chunks = chunks
        
        # ì„ë² ë”© í™•ì¸
        if self.embeddings is None:
            print("   âš ï¸ ì„ë² ë”©ì´ ì—†ìŠµë‹ˆë‹¤. ë¡œë“œ ì‹œë„...")
            if not self.load_embeddings():
                raise ValueError("ì„ë² ë”©ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì„ë² ë”© ì°¨ì›
        print(f"   - ì„ë² ë”© ì°¨ì›: {self.embeddings.shape}")
        dimension = self.embeddings.shape[1]
        
        # FAISS ì¸ë±ìŠ¤ ìƒì„± (ë‚´ì  ê¸°ë°˜)
        self.index = faiss.IndexFlatIP(dimension)
        
        # ì„ë² ë”©ì„ float32ë¡œ ë³€í™˜ (FAISS ìš”êµ¬ì‚¬í•­)
        embeddings_float32 = self.embeddings.astype('float32')
        
        # ì¸ë±ìŠ¤ì— ì„ë² ë”© ì¶”ê°€
        self.index.add(embeddings_float32)
        
        print(f"âœ… FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {self.index.ntotal}ê°œ ë²¡í„°")
        return self.index
    
    def search(
        self, 
        query: str, 
        top_k: int = 5, 
        min_score: float = 0.0
    ) -> List[Dict]:
        """
        ì¿¼ë¦¬ì— ëŒ€í•œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
        
        :param query: ê²€ìƒ‰ ì¿¼ë¦¬
        :param top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ìˆ˜
        :param min_score: ìµœì†Œ ìœ ì‚¬ë„ ì ìˆ˜
        :return: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        print(f"   ğŸ” search ë©”ì„œë“œ í˜¸ì¶œë¨")
        print(f"   - self: {self}")
        print(f"   - self.index: {self.index}")
        print(f"   - self.model: {self.model}")
        
        # ì¸ë±ìŠ¤ì™€ ëª¨ë¸ í™•ì¸
        if self.index is None:
            print("   âš ï¸ ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. load_embeddings ì‹œë„...")
            if not self.load_embeddings():
                print("   âŒ ì„ë² ë”© ë¡œë“œ ì‹¤íŒ¨")
                return []
            
            # ì¸ë±ìŠ¤ ë¹Œë“œ
            if not self.build_index():
                print("   âŒ ì¸ë±ìŠ¤ ë¹Œë“œ ì‹¤íŒ¨")
                return []
        
        if self.model is None:
            print(f"   âš ï¸ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ ë¡œë“œ ì‹œë„...")
            if self.model_name:
                from sentence_transformers import SentenceTransformer
                self.model = SentenceTransformer(self.model_name)
            else:
                print("   âŒ ëª¨ë¸ ì´ë¦„ì„ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
        
        try:
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            print(f"   - ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì¤‘...")
            query_embedding = self.model.encode(
                query,
                normalize_embeddings=True,
                convert_to_numpy=True
            )
            
            # FAISS ê²€ìƒ‰
            query_vector = query_embedding.astype('float32').reshape(1, -1)
            scores, indices = self.index.search(query_vector, top_k)
            
            # ê²°ê³¼ ìƒì„±
            results = []
            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
                if score >= min_score:
                    chunk = self.chunks[idx]
                    results.append({
                        'chunk_id': chunk.get('id', str(idx)),
                        'title': chunk.get('title', ''),
                        'content': chunk.get('content', ''),
                        'context': chunk.get('context', ''),
                        'metadata': chunk.get('metadata', {}),
                        'score': float(score),
                        'rank': i + 1
                    })
            
            print(f"   âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return results
            
        except Exception as e:
            print(f"   âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def update_index(self, new_embeddings_path: str = None):
        """
        ìƒˆë¡œìš´ ì„ë² ë”©ìœ¼ë¡œ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
        
        :param new_embeddings_path: ìƒˆë¡œìš´ ì„ë² ë”© íŒŒì¼ ê²½ë¡œ
        """
        if new_embeddings_path:
            self.embedding_path = new_embeddings_path
        
        # ì„ë² ë”© ì¬ë¡œë“œ
        self.load_embeddings()
        
        # ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
        self.build_index()
        
        print("âœ… ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
    
    def get_statistics(self) -> Dict:
        """ê²€ìƒ‰ê¸° í†µê³„ ì •ë³´"""
        stats = {
            'total_chunks': len(self.chunks) if self.chunks else 0,
            'embedding_dimension': self.embeddings.shape[1] if self.embeddings is not None else 0,
            'model_name': self.model_name,
            'index_total': self.index.ntotal if self.index else 0,
            'embedding_file': self.embedding_path
        }
        
        if self.chunks:
            # ì²­í¬ ê¸¸ì´ í†µê³„
            content_lengths = [len(chunk.get('content', '')) for chunk in self.chunks]
            stats.update({
                'avg_content_length': np.mean(content_lengths),
                'min_content_length': min(content_lengths),
                'max_content_length': max(content_lengths)
            })
        
        return stats
    
    def save_index(self, index_path: str = None):
        """
        FAISS ì¸ë±ìŠ¤ ì €ì¥
        
        :param index_path: ì €ì¥í•  ì¸ë±ìŠ¤ ê²½ë¡œ (ê¸°ë³¸ê°’: í´ë˜ìŠ¤ ì´ˆê¸°í™” ì‹œ ì„¤ì •ëœ ê²½ë¡œ)
        """
        if index_path is None:
            index_path = self.index_path
        
        if self.index is None:
            print("âŒ ì €ì¥í•  ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        os.makedirs(os.path.dirname(index_path), exist_ok=True)
        faiss.write_index(self.index, index_path)
        print(f"âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ: {index_path}")
    
    def load_index(self, index_path: str = None):
        """
        ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ ë¡œë“œ
        
        :param index_path: ë¡œë“œí•  ì¸ë±ìŠ¤ ê²½ë¡œ (ê¸°ë³¸ê°’: í´ë˜ìŠ¤ ì´ˆê¸°í™” ì‹œ ì„¤ì •ëœ ê²½ë¡œ)
        """
        if index_path is None:
            index_path = self.index_path
        
        if not os.path.exists(index_path):
            print(f"âŒ ì¸ë±ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {index_path}")
            return False
        
        try:
            self.index = faiss.read_index(index_path)
            print(f"âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {index_path}")
            return True
        except Exception as e:
            print(f"âŒ ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

def main():
    """ê²€ìƒ‰ê¸° í…ŒìŠ¤íŠ¸"""
    print("ğŸµ ìŒì•… ì´ë¡  ê²€ìƒ‰ê¸° í…ŒìŠ¤íŠ¸")
    
    try:
        # ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        retriever = VectorRetriever()
        
        # í†µê³„ ì¶œë ¥
        stats = retriever.get_statistics()
        print("\nğŸ“Š ê²€ìƒ‰ê¸° í†µê³„:")
        for key, value in stats.items():
            print(f"  - {key}: {value}")
        
        # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
        test_queries = [
            "ì„¸ì»¨ë”ë¦¬ ë„ë¯¸ë„ŒíŠ¸",
            "í™”ì„± ì§„í–‰",
            "ë©”ì´ì € ìŠ¤ì¼€ì¼",
            "ì½”ë“œ ì§„í–‰"
        ]
        
        print("\nğŸ” í…ŒìŠ¤íŠ¸ ê²€ìƒ‰:")
        for query in test_queries:
            print(f"\nì¿¼ë¦¬: '{query}'")
            results = retriever.search(query, top_k=3)
            
            for i, result in enumerate(results, 1):
                print(f"  {i}. ì ìˆ˜: {result['score']:.3f}")
                print(f"     ì œëª©: {result['title']}")
                print(f"     ë‚´ìš©: {result['content'][:80]}...")
        
        # ì¸ë±ìŠ¤ ì €ì¥
        retriever.save_index()
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()
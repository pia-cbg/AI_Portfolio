"""
ìŒì•… ì´ë¡  RAG ëª¨ë¸
- ì˜¤ì§ ë°ì´í„°ì…‹ ê¸°ë°˜ ë‹µë³€ë§Œ ì œê³µ
- ì™¸ë¶€ ì§€ì‹ ì‚¬ìš© ê¸ˆì§€
- ë°ì´í„° ë¶€ì¡± ì‹œ ëª…í™•íˆ í‘œì‹œ
"""
import os
import sys
import json
from typing import Dict, List, Tuple, Optional
from datetime import datetime
from dotenv import load_dotenv
import anthropic

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

# utils í´ë”ì˜ music_utils ì„í¬íŠ¸
from utils.music_utils import extract_musical_terms, format_chord_name

class RAGModel:
    def __init__(self, retriever, min_similarity_score: float = 0.7):
        """
        RAG ëª¨ë¸ ì´ˆê¸°í™”
        
        :param retriever: ë²¡í„° ê²€ìƒ‰ê¸°
        :param min_similarity_score: ìµœì†Œ ìœ ì‚¬ë„ ì ìˆ˜ (ê¸°ë³¸ 0.7)
        """
        # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
        env_path = os.path.join(project_root, '.env')
        load_dotenv(env_path)
        
        # API í‚¤ ë° ëª¨ë¸ ì„¤ì •
        self.api_key = os.getenv('ANTHROPIC_API_KEY')
        self.model_name = os.getenv('ANTHROPIC_MODEL', 'claude-3-haiku-20240307')
        self.min_similarity_score = min_similarity_score
        
        # Anthropic í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = self._initialize_client()
        
        # ê²€ìƒ‰ê¸° ì„¤ì •
        self.retriever = retriever
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
        self.system_prompt = self._prepare_system_prompt()
        
        # ë°ì´í„° ê°­ ì¶”ì  (ì„¸ì…˜ë³„)
        self.session_gaps = []
        
        # í†µê³„ ì¶”ì 
        self.stats = {
            'total_queries': 0,
            'successful_answers': 0,
            'partial_answers': 0,
            'no_data_answers': 0
        }
    
    def _initialize_client(self):
        """Anthropic API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            if not self.api_key:
                print("âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return None
            
            clean_key = self.api_key.strip()
            client = anthropic.Anthropic(api_key=clean_key)
            
            print("âœ… Anthropic í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
            return client
        except Exception as e:
            print(f"âŒ Anthropic í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None
    
    def _prepare_system_prompt(self) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return """
ë‹¹ì‹ ì€ ìŒì•… ì´ë¡  êµìœ¡ ì‹œìŠ¤í…œì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

## í•µì‹¬ ì›ì¹™
1. **ì˜¤ì§ ì œê³µëœ ì°¸ê³ ìë£Œë§Œ ì‚¬ìš©**: ì°¸ê³ ìë£Œì— ëª…ì‹œëœ ë‚´ìš©ë§Œ ë‹µë³€ì— í¬í•¨í•˜ì„¸ìš”.
2. **ì™¸ë¶€ ì§€ì‹ ì ˆëŒ€ ê¸ˆì§€**: ë‹¹ì‹ ì´ ì•Œê³  ìˆëŠ” ì¼ë°˜ì ì¸ ìŒì•… ì§€ì‹ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
3. **íˆ¬ëª…ì„±**: ë‹µë³€í•  ìˆ˜ ì—†ëŠ” ë¶€ë¶„ì€ ëª…í™•íˆ í‘œì‹œí•˜ì„¸ìš”.

## ë‹µë³€ ê·œì¹™
- ëª¨ë“  ì •ë³´ëŠ” ì°¸ê³ ìë£Œì—ì„œ ì§ì ‘ ì¸ìš©
- ê° ë¬¸ì¥ ëì— [ì°¸ê³ ìë£Œ ë²ˆí˜¸] í‘œì‹œ
- ì¶”ë¡ ì´ë‚˜ ìœ ì¶” ê¸ˆì§€
- ì •ë³´ê°€ ì—†ê±°ë‚˜ ë¶€ì¡±í•  ì‹œ "í˜„ì¬ ë°ì´í„°ì…‹ì´ ë¶€ì¡±í•´ì„œ ë” ì—´ì‹¬íˆ ë°°ìš°ê² ìŠµë‹ˆë‹¤. | ì´ëª¨í‹°ì½˜ ì‚¬ìš©" ëª…ì‹œ
- ë¬¸ë‹¨ë³„ ë§ˆì¹¨í‘œê°€ ìˆì„ ê²½ìš° ë‹¤ìŒ ì¤„ë¡œ ì¶œë ¥

## ë‹µë³€ êµ¬ì¡°
1. ì°¸ê³ ìë£Œì— ìˆëŠ” í•µì‹¬ ì •ë³´ ìš”ì•½
2. ì„¸ë¶€ ì„¤ëª… (ì°¸ê³ ìë£Œ í‘œì‹œ)
3. ë¶€ì¡±í•œ ì •ë³´ ëª…ì‹œ

## ìš©ì–´ ì‚¬ìš©
- ì°¸ê³ ìë£Œì˜ ìš©ì–´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
- ë²ˆì—­ì²´ ê¸ˆì§€
- ì˜ì–´ ìš©ì–´ëŠ” ì›ë¬¸ ìœ ì§€
        """
    
    def get_conversation_response(self, query: str) -> Dict:
        """RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„±"""
        self.stats['total_queries'] += 1
        
        try:
            # í´ë¼ì´ì–¸íŠ¸ í™•ì¸
            if self.client is None:
                return self._create_error_response("API í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ìŒì•… ìš©ì–´ ì¶”ì¶œ
            musical_terms = extract_musical_terms(query)
            
            # ê²€ìƒ‰ ìˆ˜í–‰ (ë” ë§ì€ ê²°ê³¼ ê²€ìƒ‰)
            sources = []
            if self.retriever is not None:
                try:
                    sources = self.retriever.search(query, top_k=5)
                    # print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(sources)}ê°œ ê²°ê³¼")
                except Exception as search_error:
                    print(f"âš ï¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {search_error}")
                    return self._create_error_response(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {search_error}")
            
            # ì†ŒìŠ¤ ë¶„ë¥˜
            high_quality_sources = [s for s in sources if s.get('score', 0) >= self.min_similarity_score]
            medium_quality_sources = [s for s in sources if 0.5 <= s.get('score', 0) < self.min_similarity_score]
            
            # ì‘ë‹µ ìƒì„± ë¡œì§
            if high_quality_sources:
                # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
                return self._generate_complete_response(query, high_quality_sources, musical_terms)
            elif medium_quality_sources:
                # ë¶€ë¶„ì  ë°ì´í„°ë§Œ ìˆëŠ” ê²½ìš°
                return self._generate_partial_response(query, medium_quality_sources, musical_terms)
            else:
                # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
                return self._generate_no_data_response(query, musical_terms)
                
        except Exception as e:
            print(f"âŒ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return self._create_error_response(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def _generate_complete_response(self, query: str, sources: List[Dict], musical_terms: List[str]) -> Dict:
        """ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆì„ ë•Œ ì‘ë‹µ ìƒì„±"""
        
        # ë””ë²„ê¹…: ì…ë ¥ ë°ì´í„° í™•ì¸
        # print(f"DEBUG: _generate_complete_response í˜¸ì¶œë¨")
        # print(f"DEBUG: ì§ˆë¬¸: {query}")
        # print(f"DEBUG: ì†ŒìŠ¤ ê°œìˆ˜: {len(sources)}")
        # print(f"DEBUG: ìŒì•… ìš©ì–´: {musical_terms}")
        
        # ì†ŒìŠ¤ í…ìŠ¤íŠ¸ ìƒì„±
        sources_text = self._format_sources_for_prompt(sources)
        
        # print(f"DEBUG: í¬ë§·ëœ ì†ŒìŠ¤ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(sources_text)}")
        # print(f"DEBUG: ì†ŒìŠ¤ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°:\n{sources_text[:500]}...")
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
    ì‚¬ìš©ì ì§ˆë¬¸: {query}

    ì°¸ê³ ìë£Œ:
    {sources_text}

    ìœ„ ì°¸ê³ ìë£Œë§Œì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
    ê° ì •ë³´ë§ˆë‹¤ [ì°¸ê³ ìë£Œ ë²ˆí˜¸]ë¥¼ í‘œì‹œí•˜ì„¸ìš”.
    ì°¸ê³ ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
        """
        
        # print(f"DEBUG: ì „ì²´ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)}")
        # print(f"DEBUG: API í˜¸ì¶œ ì¤€ë¹„ - ëª¨ë¸: {self.model_name}")
        
        try:
            # API í˜¸ì¶œ
            # print("DEBUG: Anthropic API í˜¸ì¶œ ì‹œì‘...")
            
            response = self.client.messages.create(
                model=self.model_name,
                max_tokens=1000,
                system=self.system_prompt,
                messages=[{"role": "user", "content": prompt}]
            )
            
            # print("DEBUG: API ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
            # print(f"DEBUG: ì‘ë‹µ íƒ€ì…: {type(response)}")
            # print(f"DEBUG: ì‘ë‹µ ë‚´ìš© íƒ€ì…: {type(response.content)}")
            # print(f"DEBUG: ì‘ë‹µ ë‚´ìš© ê°œìˆ˜: {len(response.content) if hasattr(response, 'content') else 'N/A'}")
            
            # ì‘ë‹µ ì¶”ì¶œ
            if hasattr(response, 'content') and len(response.content) > 0:
                answer = response.content[0].text
                # print(f"DEBUG: ì¶”ì¶œëœ ë‹µë³€ ê¸¸ì´: {len(answer)}")
                # print(f"DEBUG: ë‹µë³€ ì²˜ìŒ 200ì: {answer[:200]}...")
            else:
                # print("DEBUG: ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŒ")
                answer = "ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats['successful_answers'] += 1
            
            # ê²°ê³¼ ë°˜í™˜
            result = {
                'answer': answer,
                'sources': sources,
                'model': self.model_name,
                'musical_terms': musical_terms,
                'confidence': 'high',
                'data_coverage': 'complete'
            }
            
            # print(f"DEBUG: ë°˜í™˜í•  ê²°ê³¼ íƒ€ì…: {type(result)}")
            # print(f"DEBUG: ê²°ê³¼ í‚¤: {result.keys()}")
            
            return result
            
        except Exception as e:
            # print(f"DEBUG: API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__}: {e}")
            import traceback
            traceback.print_exc()
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
            return {
                'answer': f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}",
                'sources': sources,
                'model': self.model_name,
                'musical_terms': musical_terms,
                'confidence': 'error',
                'data_coverage': 'error'
            }
    
    def _generate_no_data_response(self, query: str, musical_terms: List[str]) -> Dict:
        """ë°ì´í„°ê°€ ì—†ì„ ë•Œ ì‘ë‹µ ìƒì„±"""
        
        # ê°­ ê¸°ë¡
        gap = {
            'query': query,
            'type': 'no_coverage',
            'musical_terms': musical_terms,
            'timestamp': datetime.now().isoformat()
        }
        self.session_gaps.append(gap)
        self.stats['no_data_answers'] += 1
        
        answer = f"""
ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ë°ì´í„°ì…‹ì— "{query}"ì— ëŒ€í•œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.

ğŸ” ê°ì§€ëœ ìŒì•… ìš©ì–´: {', '.join(musical_terms) if musical_terms else 'ì—†ìŒ'}

ì´ ì£¼ì œëŠ” í–¥í›„ ë°ì´í„°ì…‹ í™•ì¥ ì‹œ ì¶”ê°€ë  ì˜ˆì •ì…ë‹ˆë‹¤.
ë‹¤ë¥¸ ìŒì•… ì´ë¡  ê´€ë ¨ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë‹µë³€ ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤.
        """
        
        return {
            'answer': answer,
            'sources': [],
            'model': self.model_name,
            'musical_terms': musical_terms,
            'confidence': 'none',
            'data_coverage': 'none',
            'gap_recorded': True
        }
    
    def _format_sources_for_prompt(self, sources: List[Dict]) -> str:
        """í”„ë¡¬í”„íŠ¸ìš© ì†ŒìŠ¤ í¬ë§·íŒ…"""
        formatted = ""
        
        for idx, source in enumerate(sources, 1):
            title = source.get('title', 'ì œëª© ì—†ìŒ')
            content = source.get('content', 'ë‚´ìš© ì—†ìŒ')
            score = source.get('score', 0)
            
            # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°
            if len(content) > 500:
                content = content[:500] + "..."
            
            formatted += f"\n[ì°¸ê³ ìë£Œ {idx}]\n"
            formatted += f"ì œëª©: {title}\n"
            formatted += f"ë‚´ìš©: {content}\n"
            formatted += f"ê´€ë ¨ë„: {score:.3f}\n"
            formatted += "-" * 40
        
        # ë””ë²„ê¹…
        # print(f"DEBUG: í¬ë§·ëœ ì†ŒìŠ¤ ê°œìˆ˜: {len(sources)}")
        # print(f"DEBUG: í¬ë§·ëœ í…ìŠ¤íŠ¸ ì´ ê¸¸ì´: {len(formatted)}")
        
        return formatted
    
    def _create_error_response(self, error_message: str) -> Dict:
        """ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
        return {
            'answer': f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: {error_message}",
            'sources': [],
            'model': self.model_name,
            'musical_terms': [],
            'confidence': 'error',
            'data_coverage': 'error'
        }
    
    def get_session_stats(self) -> Dict:
        """í˜„ì¬ ì„¸ì…˜ í†µê³„ ë°˜í™˜"""
        return {
            'statistics': self.stats,
            'gaps_identified': len(self.session_gaps),
            'gap_details': self.session_gaps
        }
    
    def save_gaps_report(self, filename: str = None):
        """ë°ì´í„° ê°­ ë¦¬í¬íŠ¸ ì €ì¥"""
        if not self.session_gaps:
            print("ê¸°ë¡ëœ ê°­ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f'data/fine_tuning/gaps/gap_report_{timestamp}.json'
        
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        report = {
            'session_date': datetime.now().isoformat(),
            'statistics': self.stats,
            'total_gaps': len(self.session_gaps),
            'gaps': self.session_gaps
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ê°­ ë¦¬í¬íŠ¸ ì €ì¥: {filename}")
        print(f"   - ì´ ì§ˆë¬¸: {self.stats['total_queries']}")
        print(f"   - ì™„ì „ ë‹µë³€: {self.stats['successful_answers']}")
        print(f"   - ë¶€ë¶„ ë‹µë³€: {self.stats['partial_answers']}")
        print(f"   - ë‹µë³€ ë¶ˆê°€: {self.stats['no_data_answers']}")

    
    
def main():
    """RAG ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    try:
        from src.models.retriever import VectorRetriever
        retriever = VectorRetriever()
        
        print("ê²€ìƒ‰ê¸° ì´ˆê¸°í™” ì¤‘...")
        retriever.load_embeddings()
        retriever.build_index()
        
        rag_model = RAGModel(retriever)
        
        # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
        test_queries = [
            "ì„¸ì»¨ë”ë¦¬ ë„ë¯¸ë„ŒíŠ¸ë€?",
            "12 equal temperamentì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜",
            "í‰ê· ìœ¨ê³¼ ìˆœì •ë¥ ì˜ ì°¨ì´ëŠ”?"
        ]
        
        for query in test_queries:
            print(f"\n{'='*60}")
            print(f"ì§ˆë¬¸: {query}")
            print('='*60)
            
            response = rag_model.get_conversation_response(query)
            
            print("\në‹µë³€:")
            print(response['answer'])
            print(f"\nì‹ ë¢°ë„: {response['confidence']}")
            print(f"ë°ì´í„° ì»¤ë²„ë¦¬ì§€: {response['data_coverage']}")
        
        # ì„¸ì…˜ í†µê³„ ë° ê°­ ë¦¬í¬íŠ¸
        print("\nğŸ“Š ì„¸ì…˜ í†µê³„:")
        stats = rag_model.get_session_stats()
        print(json.dumps(stats['statistics'], indent=2))
        
        # ê°­ ë¦¬í¬íŠ¸ ì €ì¥
        rag_model.save_gaps_report()
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
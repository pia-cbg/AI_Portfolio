import json
import os
from typing import Dict, List, Any
import hashlib

class MusicTheoryDataLoader:
    def __init__(self, json_path: str = 'data/raw/music_theory_curriculum.json'):
        """
        ìŒì•… ì´ë¡  JSON ë°ì´í„° ë¡œë”
        
        :param json_path: JSON íŒŒì¼ ê²½ë¡œ
        """
        self.json_path = json_path
        self.data = None
        self.chunks = []
    
    def load_data(self) -> Dict:
        """JSON íŒŒì¼ ë¡œë“œ"""
        try:
            with open(self.json_path, 'r', encoding='utf-8') as f:
                self.data = json.load(f)
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {self.json_path}")
            return self.data
        except FileNotFoundError:
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.json_path}")
            return {}
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return {}
    
    def extract_text_chunks(self, min_length: int = 50) -> List[Dict]:
        if self.data is None:
            self.load_data()
        
        self.chunks = []
        
        def extract_chunks_recursive(obj, path="", parent_context=""):
            """ì¬ê·€ì ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì²­í¬ ì¶”ì¶œ"""
            if isinstance(obj, dict):
                # íŠ¹ì • í‚¤ì›Œë“œê°€ ìˆëŠ” ì„¹ì…˜ë§Œ ì²˜ë¦¬
                for key, value in obj.items():
                    # ë©”íƒ€ë°ì´í„°ì™€ ìƒìˆ˜ ì œì™¸
                    if key not in ['metadata', 'constants']:
                        current_path = f"{path}.{key}" if path else key
                        current_context = f"{parent_context} > {key}".strip(" >")
                        
                        # í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ
                        content = ""
                        if isinstance(value, dict):
                            # ë”•ì…”ë„ˆë¦¬ë¼ë©´ JSONìœ¼ë¡œ ë³€í™˜í•´ì„œ í…ìŠ¤íŠ¸ë¡œ
                            content = json.dumps(value, ensure_ascii=False)
                        elif isinstance(value, (str, int, float, bool)):
                            # ê¸°ë³¸ íƒ€ì…ì´ë©´ ë¬¸ìì—´ë¡œ ë³€í™˜
                            content = str(value)
                        
                        # ì²­í¬ ìƒì„± (content ë³´ì¥)
                        chunk = {
                            'id': self._generate_chunk_id(current_path),
                            'title': key.replace('_', ' ').title(),
                            'content': content,
                            'path': current_path,
                            'context': current_context
                        }
                        
                        # ìµœì†Œ ê¸¸ì´ ì²´í¬
                        if len(content) >= min_length:
                            self.chunks.append(chunk)
                        
                        # ì¬ê·€ì  íƒìƒ‰
                        if isinstance(value, dict):
                            extract_chunks_recursive(value, current_path, current_context)
                            
            elif isinstance(obj, list):
                for i, item in enumerate(obj):
                    new_path = f"{path}[{i}]"
                    extract_chunks_recursive(item, new_path, parent_context)
        
        # ìµœìƒìœ„ ë ˆë²¨ë¶€í„° ì¬ê·€ ì‹œì‘
        extract_chunks_recursive(self.data)
        
        print(f"âœ… {len(self.chunks)}ê°œì˜ í…ìŠ¤íŠ¸ ì²­í¬ ì¶”ì¶œ ì™„ë£Œ")
        return self.chunks
    
    def _extract_chunks_recursive(self, obj: Any, path: str = "", parent_context: str = ""):
        """ì¬ê·€ì ìœ¼ë¡œ ì²­í¬ ì¶”ì¶œ"""
        if isinstance(obj, dict):
            # í˜„ì¬ ë ˆë²¨ì˜ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            current_context = self._build_context(obj, parent_context)
            
            # ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ í•„ë“œ í™•ì¸
            content_fields = ['description', 'explanation', 'definition', 'content', 'detailed_explanation']
            
            for field in content_fields:
                if field in obj and isinstance(obj[field], str) and obj[field].strip():
                    chunk = {
                        'id': self._generate_chunk_id(path + f".{field}"),
                        'content': obj[field],
                        'title': obj.get('title', obj.get('name', path.split('.')[-1])),
                        'path': path,
                        'context': current_context,
                        'metadata': self._extract_metadata(obj)
                    }
                    self.chunks.append(chunk)
            
            # ì¬ê·€ì  íƒìƒ‰
            for key, value in obj.items():
                if key not in content_fields:
                    new_path = f"{path}.{key}" if path else key
                    self._extract_chunks_recursive(value, new_path, current_context)
                    
        elif isinstance(obj, list):
            for idx, item in enumerate(obj):
                new_path = f"{path}[{idx}]"
                self._extract_chunks_recursive(item, new_path, parent_context)
    
    def _build_context(self, obj: Dict, parent_context: str) -> str:
        """í˜„ì¬ ê°ì²´ì˜ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        context_parts = []
        
        if parent_context:
            context_parts.append(parent_context)
        
        # ì œëª©ì´ë‚˜ ì´ë¦„ ì¶”ê°€
        if 'title' in obj:
            context_parts.append(f"ì£¼ì œ: {obj['title']}")
        elif 'name' in obj:
            context_parts.append(f"ê°œë…: {obj['name']}")
        
        # ì¹´í…Œê³ ë¦¬ë‚˜ íƒ€ì… ì •ë³´
        if 'category' in obj:
            context_parts.append(f"ì¹´í…Œê³ ë¦¬: {obj['category']}")
        if 'type' in obj:
            context_parts.append(f"ìœ í˜•: {obj['type']}")
        
        return " > ".join(context_parts)
    
    def _extract_metadata(self, obj: Dict) -> Dict:
        """ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        metadata = {}
        
        # ì¤‘ìš”í•œ ë©”íƒ€ë°ì´í„° í•„ë“œë“¤
        metadata_fields = [
            'level', 'difficulty', 'category', 'type', 
            'prerequisites', 'related_concepts', 'examples'
        ]
        
        for field in metadata_fields:
            if field in obj:
                metadata[field] = obj[field]
        
        return metadata
    
    def _generate_chunk_id(self, path: str) -> str:
        """ê²½ë¡œ ê¸°ë°˜ ê³ ìœ  ID ìƒì„±"""
        return hashlib.md5(path.encode()).hexdigest()[:8]
    
    def get_chunk_by_id(self, chunk_id: str) -> Dict:
        """IDë¡œ ì²­í¬ ê²€ìƒ‰"""
        for chunk in self.chunks:
            if chunk['id'] == chunk_id:
                return chunk
        return None
    
    def search_chunks(self, keyword: str) -> List[Dict]:
        """í‚¤ì›Œë“œë¡œ ì²­í¬ ê²€ìƒ‰"""
        keyword_lower = keyword.lower()
        matching_chunks = []
        
        for chunk in self.chunks:
            if (keyword_lower in chunk.get('content', '').lower() or
                keyword_lower in chunk.get('title', '').lower() or
                keyword_lower in chunk.get('context', '').lower()):
                matching_chunks.append(chunk)
        
        return matching_chunks
    
    def get_statistics(self) -> Dict:
        """ë°ì´í„° í†µê³„"""
        if not self.chunks:
            self.extract_text_chunks()
        
        stats = {
            'total_chunks': len(self.chunks),
            'avg_chunk_length': sum(len(c['content']) for c in self.chunks) / len(self.chunks) if self.chunks else 0,
            'unique_titles': len(set(c.get('title', '') for c in self.chunks)),
            'paths': len(set(c['path'] for c in self.chunks))
        }
        
        return stats
    
    def save_chunks(self, output_path: str = 'data/processed/chunks.json'):
        """ì²­í¬ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.chunks, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ì²­í¬ ì €ì¥ ì™„ë£Œ: {output_path}")

def main():
    # ë°ì´í„° ë¡œë” í…ŒìŠ¤íŠ¸
    loader = MusicTheoryDataLoader()
    
    # ë°ì´í„° ë¡œë“œ
    data = loader.load_data()
    
    # ì²­í¬ ì¶”ì¶œ
    chunks = loader.extract_text_chunks()
    
    # í†µê³„ ì¶œë ¥
    stats = loader.get_statistics()
    print("\nğŸ“Š ë°ì´í„° í†µê³„:")
    for key, value in stats.items():
        print(f"  - {key}: {value}")
    
    # ìƒ˜í”Œ ì²­í¬ ì¶œë ¥
    if chunks:
        print("\nğŸ“ ìƒ˜í”Œ ì²­í¬:")
        sample = chunks[0]
        print(f"  - ID: {sample['id']}")
        print(f"  - Title: {sample['title']}")
        print(f"  - Content: {sample['content'][:100]}...")
    
    # ì²­í¬ ì €ì¥
    loader.save_chunks()

if __name__ == "__main__":
    main()
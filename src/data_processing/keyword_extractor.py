import numpy as np
import json
import re
import os
from typing import List, Dict, Set
from sklearn.feature_extraction.text import TfidfVectorizer

class KeywordExtractor:
    def __init__(self, json_path='data/raw/music_theory_curriculum.json'):
        self.json_path = json_path
        self.data = self.load_json_data()
        self.music_whitelist = self._load_music_whitelist()

    def _load_music_whitelist(self) -> Set[str]:
        """ì£¼ìš” ìŒì•… ì´ë¡  ìš©ì–´ ë¦¬ìŠ¤íŠ¸"""
        return {
            "ì½”ë“œ", "í™”ìŒ", "ìŠ¤ì¼€ì¼", "ìŒê³„", "ì¡°ì„±", "í™”ì„±", "ì§„í–‰", "ìŒì •", "ë¦¬ë“¬", "ë©œë¡œë””", "ë°•ì",
            "ë„ë¯¸ë„ŒíŠ¸", "í† ë‹‰", "ì„œë¸Œë„ë¯¸ë„ŒíŠ¸", "í‘ì…˜", "ê¸°ëŠ¥", "íŠ¸ë¼ì´ì–´ë“œ", "ì„¸ë¸ìŠ¤", "íŠ¸ë¼ì´í†¤",
            "ë©”ì´ì €", "ë§ˆì´ë„ˆ", "ë””ë¯¸ë‹ˆì‰¬ë“œ", "ì–´ê·¸ë©˜í‹°ë“œ", "ì„œìŠ¤íœë””ë“œ", "ìµìŠ¤í…ë””ë“œ",
            "ì„¸ì»¨ë”ë¦¬ë„ë¯¸ë„ŒíŠ¸", "ë…¼ë‹¤ì´ì•„í† ë‹‰", "ë‹¤ì´ì•„í† ë‹‰", "ë¦¬í•˜ëª¨ë‚˜ì´ì œì´ì…˜", "ëª¨ë“œ", "ëª¨ë‹¬",
            "íŠ¸ë¼ì´í†¤ì„œë¸ŒìŠ¤í‹°íŠœì…˜", "íœíƒ€í† ë‹‰", "ë¸”ë£¨ìŠ¤", "í…ì…˜", "ì–¼í„°ë ˆì´ì…˜",
            "ê°•ì§„í–‰", "ì•½ì§„í–‰", "ìˆœì°¨ì§„í–‰", "ë„ì•½ì§„í–‰", "ë³‘ì§„í–‰", "ë°˜ì§„í–‰", "ì‚¬ì„±ë¶€",
            "í”„ë ˆì´ì¦ˆ", "ëª¨í‹°ë¸Œ", "ì¼€ì´ë˜ìŠ¤", "ì¢…ì§€", "ì•„ë¥´í˜ì§€ì˜¤", "ë³´ì´ì‹±", "ì¸ë²„ì „", "ì „ìœ„",
            "ì‹±ì½”í˜ì´ì…˜", "í—¤ë¯¸ì˜¬ë¼", "í´ë¦¬ë¦¬ë“¬", "ìŠ¤ìœ™", "ì…”í”Œ", "ê·¸ë£¨ë¸Œ",
            "ê°€ì´ë“œí†¤", "í¬ë¡œë§¤í‹±", "ì—”í•˜ëª¨ë‹‰", "ëª¨ë“ˆë ˆì´ì…˜", "íŠ¸ëœìŠ¤í¬ì§€ì…˜",
            "í˜ë‹¬í¬ì¸íŠ¸", "ì˜¤ìŠ¤í‹°ë‚˜í† ", "ì¹´ìš´í„°í¬ì¸íŠ¸", "ëŒ€ìœ„ë²•", "AP ë…¸íŠ¸", "í˜ë‹¬", "ì„œìŠ¤4",
            # í•„ìš” ì‹œ í™•ì¥
        }

    def load_json_data(self) -> Dict:
        try:
            with open(self.json_path, 'r', encoding='utf-8') as file:
                return json.load(file)
        except FileNotFoundError:
            print(f"âŒ íŒŒì¼ ì—†ìŒ: {self.json_path}")
            return {}
        except json.JSONDecodeError:
            print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {self.json_path}")
            return {}

    def extract_text_corpus(self) -> List[str]:
        """JSON ë°ì´í„°ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        corpus = []
        def extract(obj):
            if isinstance(obj, dict):
                for key, value in obj.items():
                    # í‚¤ ì´ë¦„ë„ ì •ë³´ë¡œ í¬í•¨
                    if key not in ['metadata', 'constants']:
                        corpus.append(key.replace('_', ' '))
                    if isinstance(value, str) and len(value.strip()) > 5:
                        corpus.append(value.strip())
                    elif isinstance(value, (dict, list)):
                        extract(value)
            elif isinstance(obj, list):
                for item in obj:
                    extract(item)
        extract(self.data)
        print(f"ğŸ“¦ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê°œìˆ˜: {len(corpus)}")
        return corpus

    def is_music_word(self, word: str, whitelist: Set[str]) -> bool:
        word = word.lower().strip()
        return any(w in word or word in w for w in whitelist)

    def extract_keywords_with_tfidf(self, corpus: List[str], top_n: int = 200) -> Set[str]:
        """TF-IDFë¡œ ìŒì•…ì  ìš©ì–´ë§Œ ìš°ì„  ì¶”ì¶œ, ë¹„ìŒì•…ì–´ ìµœì†Œí™”"""
        def preprocess(text):
            text = re.sub(r'[^\w\s#â™­â™¯Â°]', ' ', text)
            return text.lower()
        korean_stopwords = ['ì˜','ë¥¼','ì€','ëŠ”','ì´','ê°€','ì—','ì„œ','ë¡œ','ê³¼','ì™€','ë“±','ë°','ë˜í•œ','ë•Œë¬¸ì—','í†µí•´','ìœ„í•´','ë•Œ']
        english_stopwords = ['a','an','the','and','or','but','in','on','at','to','for','of','with','by']
        stopwords = korean_stopwords + english_stopwords

        pre_corpus = [preprocess(doc) for doc in corpus]

        vectorizer = TfidfVectorizer(
            stop_words=stopwords,
            max_features=500,
            min_df=2,
            max_df=0.8,
            ngram_range=(1,2)
        )
        try:
            tfidf_matrix = vectorizer.fit_transform(pre_corpus)
        except ValueError as e:
            print(f"TF-IDF ì˜¤ë¥˜: {e}")
            return set()
        feature_names = vectorizer.get_feature_names_out()
        tfidf_scores = tfidf_matrix.sum(axis=0).A1
        word_scores = list(zip(feature_names, tfidf_scores))
        word_scores.sort(key=lambda x: x[1], reverse=True)

        whitelist = self.music_whitelist
        wh_items, music_items, other_items = [], [], []
        for word, score in word_scores:
            w = word.strip().lower()
            if self.is_music_word(w, whitelist):
                wh_items.append(w)
            elif self._is_music_pattern(w):
                music_items.append(w)
            else:
                other_items.append(w)
        # ìš°ì„ ìˆœìœ„: 1) í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ 2) ìŒì•…íŒ¨í„´ 3) ë‚˜ë¨¸ì§€
        result = list(dict.fromkeys(wh_items))
        need = top_n - len(result)
        if need > 0:
            result.extend([w for w in music_items if w not in result][:need])
        need = top_n - len(result)
        if need > 0:
            result.extend([w for w in other_items if w not in result][:need])
        return set(result[:top_n])

    def _is_music_pattern(self, word: str) -> bool:
        # ì½”ë“œëª…, ë¡œë§ˆìˆ«ì, ìŒì•… íŠ¹ìˆ˜ë¬¸ì ë“±
        if re.match(r'^[A-G][#â™­b]?(\w+)?\d*$', word): return True
        if re.match(r'^[ivIV]+[mM]?\d*$', word): return True
        if re.search(r'[#â™­â™¯Â°]', word): return True
        # ì˜ì–´ ì•½ì–´ë‚˜ íŠ¹ìˆ˜ ìš©ì–´ë„ ì¶”ê°€ í™•ëŒ€
        for pat in ['sus', 'dim', 'aug', 'maj', 'min', 'triad', 'tension', 'voice', 'mode', 'arpeggio']:
            if pat in word: return True
        return False

    def extract_named_entities(self) -> Set[str]:
        """JSONì—ì„œ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ë§Œ í†µê³¼í•˜ë„ë¡"""
        entities = set()
        def recursive(obj):
            if isinstance(obj, dict):
                for key in ['title','name','concept','definition','term']:
                    if key in obj and isinstance(obj[key], str):
                        e = obj[key].strip()
                        if len(e) > 1 and self.is_music_word(e, self.music_whitelist):
                            entities.add(e)
                for v in obj.values():
                    recursive(v)
            elif isinstance(obj, list):
                for item in obj:
                    recursive(item)
        recursive(self.data)
        print(f"ğŸ¼ ëª…ì‹œì  ìŒì•… ê°œë… ì¶”ì¶œ: {len(entities)}ê°œ")
        return entities

    def process(self, top_n: int = 200) -> Set[str]:
        corpus = self.extract_text_corpus()
        if not corpus:
            print("âŒ ì¶”ì¶œí•  í…ìŠ¤íŠ¸ ì—†ìŒ.")
            return set()
        tfidf_keywords = self.extract_keywords_with_tfidf(corpus, top_n)
        named_entities = self.extract_named_entities()
        # í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ë‹¨ì–´ëŠ” corpusì— ë“±ì¥í•˜ì§€ ì•Šì•„ë„ ë¬´ì¡°ê±´ ë„£ìŒ(ìŒì•…ì  ìš©ì–´ ìµœëŒ€ í™•ë³´)
        for white in self.music_whitelist:
            tfidf_keywords.add(white)
        all_keywords = tfidf_keywords.union(named_entities)
        print(f"ğŸµ ìµœì¢… í‚¤ì›Œë“œ (ì¤‘ë³µì œê±°): {len(all_keywords)}ê°œ")
        return all_keywords

    def save_keywords(self, keywords: Set[str]):
        keywords_dir = "data/fine_tuning/keywords"
        os.makedirs(keywords_dir, exist_ok=True)
        file_path = os.path.join(keywords_dir, "extracted_keywords.json")
        kw_list = sorted(list(keywords), key=lambda x: (-len(x.split()), x))
        with open(file_path, "w", encoding='utf-8') as f:
            json.dump(kw_list, f, ensure_ascii=False, indent=2)
        print(f"âœ… í‚¤ì›Œë“œ {len(kw_list)}ê°œ ì €ì¥ ì™„ë£Œ: {file_path}")
        print("ìƒ˜í”Œ:", ", ".join(kw_list[:10]))
        return kw_list

def main():
    extractor = KeywordExtractor()
    keywords = extractor.process(top_n=200)
    extractor.save_keywords(keywords)

if __name__ == "__main__":
    main()
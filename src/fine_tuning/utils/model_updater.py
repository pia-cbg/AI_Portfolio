import json
import os
import re
import shutil
from datetime import datetime
from typing import Dict, List, Optional, Tuple

class ModelUpdater:
    def __init__(self, 
                 raw_data_path: str = 'data/raw/music_theory_curriculum.json',
                 base_path: str = 'data/fine_tuning'):
        """
        ëª¨ë¸ ì—…ë°ì´íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        :param raw_data_path: ì›ë³¸ JSON ë°ì´í„° ê²½ë¡œ
        :param base_path: íŒŒì¸íŠœë‹ ë°ì´í„° ê²½ë¡œ
        """
        self.raw_data_path = raw_data_path
        self.base_path = base_path
        # ê²½ë¡œ ìˆ˜ì •
        self.corrections_path = os.path.join(base_path, 'corrections')
        
        # ì›ë³¸ ë°ì´í„° ë¡œë“œ
        self.raw_data = self._load_raw_data()
        
        # ì—…ë°ì´íŠ¸ ì´ë ¥
        self.update_history = []
    
    def _load_raw_data(self) -> Dict:
        """ì›ë³¸ JSON ë°ì´í„° ë¡œë“œ"""
        try:
            with open(self.raw_data_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError) as e:
            print(f"ì›ë³¸ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            return {}
    
    def _save_raw_data(self):
        """ìˆ˜ì •ëœ ë°ì´í„° ì €ì¥"""
        # ë°±ì—… ìƒì„±
        self._create_backup()
        
        # ì €ì¥
        try:
            with open(self.raw_data_path, 'w', encoding='utf-8') as f:
                json.dump(self.raw_data, f, ensure_ascii=False, indent=2)
            print(f"âœ… ì›ë³¸ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ: {self.raw_data_path}")
        except Exception as e:
            print(f"âŒ ë°ì´í„° ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def _create_backup(self):
        """ì›ë³¸ ë°ì´í„° ë°±ì—… ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = "data/raw/backups"
        os.makedirs(backup_dir, exist_ok=True)
        
        backup_path = os.path.join(backup_dir, f"music_theory_curriculum_{timestamp}.json")
        shutil.copy2(self.raw_data_path, backup_path)
        print(f"ğŸ“ ì›ë³¸ ë°ì´í„° ë°±ì—… ìƒì„±: {backup_path}")
    
    def load_corrections(self) -> List[Dict]:
        """corrections íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ (ìƒˆë¡œìš´ ê²½ë¡œ)"""
        corrections = []
        
        # ìƒˆë¡œìš´ ê²½ë¡œ: aggregated/all_corrections.json
        all_corrections_file = os.path.join(self.base_path, 'aggregated', 'all_corrections.json')
        if os.path.exists(all_corrections_file):
            try:
                with open(all_corrections_file, 'r', encoding='utf-8') as f:
                    corrections = json.load(f)
                print(f"âœ… {len(corrections)}ê°œì˜ correction ë¡œë“œë¨")
            except Exception as e:
                print(f"âŒ corrections ë¡œë“œ ì˜¤ë¥˜: {e}")
        else:
            # êµ¬ ê²½ë¡œë„ í™•ì¸ (í˜¸í™˜ì„±)
            old_corrections_file = os.path.join(self.corrections_path, 'all_corrections.json')
            if os.path.exists(old_corrections_file):
                try:
                    with open(old_corrections_file, 'r', encoding='utf-8') as f:
                        corrections = json.load(f)
                    print(f"âœ… êµ¬ ê²½ë¡œì—ì„œ {len(corrections)}ê°œì˜ correction ë¡œë“œë¨")
                except Exception as e:
                    print(f"âŒ corrections ë¡œë“œ ì˜¤ë¥˜: {e}")
            else:
                print(f"âŒ corrections íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:")
                print(f"   - ì‹ ê·œ ê²½ë¡œ: {all_corrections_file}")
                print(f"   - êµ¬ ê²½ë¡œ: {old_corrections_file}")
        
        return corrections
    
    def process_all_corrections(self):
        """ëª¨ë“  correction ì²˜ë¦¬ (ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ì—°ë™)"""
        corrections = self.load_corrections()
        
        if not corrections:
            print("ì²˜ë¦¬í•  correctionì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        corrections_made = 0
        
        for correction in corrections:
            avg_score = correction.get('avg_score', 0)
            
            # ì ìˆ˜ ê¸°ë°˜ í•„í„°ë§
            if avg_score < 4:
                print(f"âŒ ì ìˆ˜ ë„ˆë¬´ ë‚®ìŒ ({avg_score:.1f}). ê±´ë„ˆëœ€: {correction.get('question', '')[:30]}...")
                continue
            
            try:
                success = self._apply_correction_from_data(correction)
                if success:
                    corrections_made += 1
                    print(f"âœ… ì ìš© ì™„ë£Œ ({avg_score:.1f}ì ): {correction.get('question', '')[:30]}...")
            except Exception as e:
                print(f"âŒ ìˆ˜ì • ì ìš© ì¤‘ ì˜¤ë¥˜: {e}")
        
        if corrections_made > 0:
            # ë°ì´í„° ì €ì¥
            self._save_raw_data()
            
            # ì„ë² ë”© ì¬ìƒì„±
            self._regenerate_embeddings()
            
            print(f"\nğŸ‰ {corrections_made}ê°œì˜ ìˆ˜ì •ì‚¬í•­ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("ì ìš©í•  ìˆ˜ì •ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    def _apply_correction_from_data(self, correction: Dict) -> bool:
        """correction ë°ì´í„°ì—ì„œ ìˆ˜ì •ì‚¬í•­ ì ìš©"""
        question = correction.get('question', '')
        original_answer = correction.get('original_response', '')
        corrected_answer = correction.get('corrected_response', '')
        avg_score = correction.get('avg_score', 0)
        
        if not corrected_answer:
            return False
        
        # ì ìˆ˜ ê¸°ë°˜ ì—…ë°ì´íŠ¸ ì „ëµ
        if avg_score < 6:
            # ë‚®ì€ ì ìˆ˜: ì™„ì „ êµì²´
            final_response = corrected_answer
            update_type = "ì™„ì „ êµì²´"
        else:
            # ë†’ì€ ì ìˆ˜: ë‚´ìš© í•©ì¹˜ê¸°
            final_response = self._simple_merge(original_answer, corrected_answer)
            update_type = "ë‚´ìš© í•©ì¹˜ê¸°"
        
        print(f"ğŸ“ {update_type} (ì ìˆ˜: {avg_score:.1f})")
        
        # ê´€ë ¨ ì„¹ì…˜ ì°¾ê¸°
        target_section, section_path = self._find_related_section(question, original_answer)
        
        if target_section:
            # ì—…ë°ì´íŠ¸ ì ìš©
            update_success = self._update_section(target_section, final_response, question)
            
            if update_success:
                # ì—…ë°ì´íŠ¸ ì´ë ¥ ê¸°ë¡
                self.update_history.append({
                    'timestamp': datetime.now().isoformat(),
                    'question': question,
                    'section_path': section_path,
                    'update_type': update_type,
                    'score': avg_score
                })
                return True
        
        return False
    
    def _simple_merge(self, original: str, corrected: str) -> str:
        """ë‹¨ìˆœí•˜ê²Œ ì›ë³¸ + ìˆ˜ì •ì‚¬í•­ í•©ì¹˜ê¸°"""
        if not corrected:
            return original
        return f"{original}\n\n{corrected}"
    
    def _find_related_section(self, question: str, answer: str) -> Tuple[Optional[Dict], Optional[str]]:
        """ì§ˆë¬¸ê³¼ ë‹µë³€ì— ê´€ë ¨ëœ JSON ì„¹ì…˜ ì°¾ê¸°"""
        # ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords_from_text(question + " " + answer)
        
        # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì„¹ì…˜ ì°¾ê¸°
        best_section = None
        best_path = None
        best_score = 0
        
        def search_recursively(obj, path=""):
            nonlocal best_section, best_path, best_score
            
            if isinstance(obj, dict):
                # í˜„ì¬ ì„¹ì…˜ì˜ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
                score = self._calculate_relevance_score(obj, keywords)
                
                if score > best_score:
                    best_score = score
                    best_section = obj
                    best_path = path
                
                # ì¬ê·€ì  íƒìƒ‰
                for key, value in obj.items():
                    new_path = f"{path}.{key}" if path else key
                    search_recursively(value, new_path)
                    
            elif isinstance(obj, list):
                for i, item in enumerate(obj):
                    new_path = f"{path}[{i}]"
                    search_recursively(item, new_path)
        
        search_recursively(self.raw_data)
        
        return best_section, best_path
    
    def _extract_keywords_from_text(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ì¶”ì¶œ
        words = re.findall(r'\b[\wê°€-í£]+\b', text.lower())
        
        # ê¸¸ì´ê°€ 2 ì´ìƒì¸ ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ë§Œ ì„ íƒ
        keywords = [word for word in words if len(word) >= 2]
        
        # ì¤‘ë³µ ì œê±°í•˜ê³  ë¹ˆë„ìˆœ ì •ë ¬
        from collections import Counter
        word_counts = Counter(keywords)
        
        return [word for word, count in word_counts.most_common(10)]
    
    def _calculate_relevance_score(self, section: Dict, keywords: List[str]) -> float:
        """ì„¹ì…˜ê³¼ í‚¤ì›Œë“œì˜ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        if not keywords:
            return 0
        
        # ì„¹ì…˜ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        section_text = ""
        
        def collect_text(obj):
            nonlocal section_text
            
            if isinstance(obj, str):
                section_text += " " + obj.lower()
            elif isinstance(obj, dict):
                for value in obj.values():
                    collect_text(value)
            elif isinstance(obj, list):
                for item in obj:
                    collect_text(item)
        
        collect_text(section)
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        matches = 0
        for keyword in keywords:
            if keyword in section_text:
                matches += 1
        
        return matches / len(keywords) if keywords else 0
    
    def _update_section(self, section: Dict, final_response: str, question: str) -> bool:
        """ì„¹ì…˜ ì—…ë°ì´íŠ¸"""
        # ì—…ë°ì´íŠ¸í•  í•„ë“œ ì°¾ê¸°
        update_fields = ['description', 'explanation', 'detailed_explanation', 'definition']
        
        for field in update_fields:
            if field in section:
                # ê¸°ì¡´ ë‚´ìš©ì´ ìˆë‹¤ë©´ ë³´ê°•
                existing_content = section[field]
                
                # ë‚´ìš© ìœ ì‚¬ì„± í™•ì¸
                similarity = self._calculate_text_similarity(existing_content, final_response)
                
                if similarity > 0.3:  # ìœ ì‚¬ë„ê°€ ë†’ìœ¼ë©´ êµì²´
                    section[field] = final_response
                    print(f"í•„ë“œ '{field}' ì—…ë°ì´íŠ¸ë¨")
                    return True
                elif len(final_response) > len(existing_content):  # ë” ìƒì„¸í•œ ë‚´ìš©ì´ë©´ êµì²´
                    section[field] = final_response
                    print(f"í•„ë“œ '{field}' í™•ì¥ë¨")
                    return True
        
        # ì ì ˆí•œ í•„ë“œê°€ ì—†ìœ¼ë©´ ìƒˆ í•„ë“œ ì¶”ê°€
        if 'improved_explanation' not in section:
            section['improved_explanation'] = final_response
            print("ìƒˆ í•„ë“œ 'improved_explanation' ì¶”ê°€ë¨")
            return True
        
        return False
    
    def _calculate_text_similarity(self, text1: str, text2: str) -> float:
        """ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°"""
        words1 = set(re.findall(r'\b[\wê°€-í£]+\b', text1.lower()))
        words2 = set(re.findall(r'\b[\wê°€-í£]+\b', text2.lower()))
        
        if not words1 or not words2:
            return 0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union) if union else 0
    
    def _regenerate_embeddings(self):
        """ì„ë² ë”© ì¬ìƒì„± (ê²½ë¡œ ìˆ˜ì •)"""
        try:
            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì°¾ê¸°
            current_file = os.path.abspath(__file__)
            project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(current_file))))
            
            import sys
            if project_root not in sys.path:
                sys.path.insert(0, project_root)
            
            from src.data_processing.json_loader import MusicTheoryDataLoader
            from src.data_processing.embedding_generator import EmbeddingGenerator
            
            print("ğŸ”„ ì„ë² ë”© ì¬ìƒì„± ì¤‘...")
            
            # ë°ì´í„° ë¡œë“œ
            loader = MusicTheoryDataLoader()
            loader.load_data()
            chunks = loader.extract_text_chunks()
            
            # ì„ë² ë”© ìƒì„±
            embedder = EmbeddingGenerator()
            embedder.generate_embeddings(chunks)
            embedder.save_embeddings()
            
            print("âœ… ì„ë² ë”© ì¬ìƒì„± ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ì„ë² ë”© ì¬ìƒì„± ì˜¤ë¥˜: {e}")
            print("ìˆ˜ë™ìœ¼ë¡œ ì„ë² ë”©ì„ ì¬ìƒì„±í•˜ì„¸ìš”:")
            print("python src/data_processing/embedding_generator.py")
            return False
    
    def get_update_history(self) -> List[Dict]:
        """ì—…ë°ì´íŠ¸ ì´ë ¥ ë°˜í™˜"""
        return self.update_history
    
    def save_update_log(self):
        """ì—…ë°ì´íŠ¸ ë¡œê·¸ ì €ì¥"""
        if not self.update_history:
            return
        
        log_dir = os.path.join(self.base_path, 'corrections')
        os.makedirs(log_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = os.path.join(log_dir, f"model_update_{timestamp}.json")
        
        log_data = {
            'update_time': timestamp,
            'total_updates': len(self.update_history),
            'updates': self.update_history
        }
        
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(log_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ì—…ë°ì´íŠ¸ ë¡œê·¸ ì €ì¥: {log_file}")
    
    def rollback_to_backup(self, backup_timestamp: str):
        """ë°±ì—…ìœ¼ë¡œ ë¡¤ë°±"""
        backup_file = f"data/raw/backups/music_theory_curriculum_{backup_timestamp}.json"
        
        if not os.path.exists(backup_file):
            print(f"âŒ ë°±ì—… íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {backup_file}")
            return False
        
        try:
            shutil.copy2(backup_file, self.raw_data_path)
            print(f"âœ… {backup_timestamp} ë°±ì—…ìœ¼ë¡œ ë¡¤ë°± ì™„ë£Œ")
            
            # ì„ë² ë”© ì¬ìƒì„±
            self._regenerate_embeddings()
            
            return True
        except Exception as e:
            print(f"âŒ ë¡¤ë°± ì¤‘ ì˜¤ë¥˜: {e}")
            return False

def main():
    """ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ì—°ë™ëœ ëª¨ë¸ ì—…ë°ì´í„°"""
    updater = ModelUpdater()
    updater.process_all_corrections()
    updater.save_update_log()

if __name__ == "__main__":
    main()
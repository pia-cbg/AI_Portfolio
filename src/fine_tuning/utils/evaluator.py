"""
íŒŒì¸íŠœë‹ í‰ê°€ ì‹œìŠ¤í…œ
- ë‹µë³€ í‰ê°€ ë° ì €ì¥
- ì„¸ì…˜ ê´€ë¦¬
- ê°œì„  ë¦¬í¬íŠ¸ ìƒì„±
"""
import os
import json
from datetime import datetime
from typing import Dict, List, Any, Optional

class FineTuningEvaluator:
    def __init__(self, base_path='data/fine_tuning'):
        """
        í‰ê°€ ë°ì´í„° ê´€ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì„¸ì…˜ë³„ ê´€ë¦¬)
        
        :param base_path: íŒŒì¸íŠœë‹ ë°ì´í„° ì €ì¥ ê²½ë¡œ
        """
        self.base_path = base_path
        self.sessions_path = os.path.join(base_path, 'sessions')
        self.aggregated_path = os.path.join(base_path, 'aggregated')
        
        # í˜„ì¬ ì„¸ì…˜ ì„¤ì •
        self.current_session = self._get_or_create_session()
        self.session_dir = os.path.join(self.sessions_path, self.current_session)
        
        # ì„¸ì…˜ë³„ ê²½ë¡œ
        self.evaluations_path = os.path.join(self.session_dir, 'evaluations')
        self.corrections_path = os.path.join(self.session_dir, 'corrections')
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self._create_directories()
        
        # í‰ê°€ ê¸°ì¤€ ë¡œë“œ
        self.criteria = self._load_evaluation_criteria()
        
        # í‰ê°€ ë°ì´í„° ìºì‹œ
        self.current_session_evaluations = []
        
        print(f"ğŸ“ í˜„ì¬ ì„¸ì…˜: {self.current_session}")
    
    def _get_or_create_session(self) -> str:
        """í˜„ì¬ ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒˆ ì„¸ì…˜ ìƒì„±"""
        os.makedirs(self.sessions_path, exist_ok=True)
        
        # ê¸°ì¡´ ì„¸ì…˜ë“¤ í™•ì¸
        existing_sessions = [d for d in os.listdir(self.sessions_path) 
                           if d.startswith('session_') and os.path.isdir(os.path.join(self.sessions_path, d))]
        
        if existing_sessions:
            latest_session = sorted(existing_sessions)[-1]
            print(f"\nğŸ“‹ ê¸°ì¡´ ì„¸ì…˜ë“¤:")
            for i, session in enumerate(sorted(existing_sessions), 1):
                marker = " (ìµœì‹ )" if session == latest_session else ""
                print(f"  {i}. {session}{marker}")
            
            choice = input(f"\nìƒˆ ì„¸ì…˜ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y: ìƒˆ ì„¸ì…˜, n: ìµœì‹  ì„¸ì…˜ ê³„ì†): ").lower()
            
            if choice != 'y':
                print(f"âœ… ê¸°ì¡´ ì„¸ì…˜ ê³„ì†: {latest_session}")
                return latest_session
        
        # ìƒˆ ì„¸ì…˜ ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        session_count = len(existing_sessions) + 1
        new_session = f"session_{session_count:03d}_{timestamp}"
        
        print(f"ğŸ†• ìƒˆ ì„¸ì…˜ ìƒì„±: {new_session}")
        return new_session
    
    def _create_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        os.makedirs(self.evaluations_path, exist_ok=True)
        os.makedirs(self.corrections_path, exist_ok=True)
        os.makedirs(self.aggregated_path, exist_ok=True)
    
    def _load_evaluation_criteria(self) -> List[Dict]:
        """í‰ê°€ ê¸°ì¤€ ë¡œë“œ - ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
        # í‰ê°€ ê¸°ì¤€ íŒŒì¼ ê²½ë¡œ
        criteria_path = os.path.join(self.base_path, 'evaluation_criteria.json')
        
        # íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ë¡œë“œ
        if os.path.exists(criteria_path):
            try:
                with open(criteria_path, 'r', encoding='utf-8') as f:
                    criteria_data = json.load(f)
                    
                # ë°ì´í„° êµ¬ì¡° í™•ì¸ ë° ë³€í™˜
                if isinstance(criteria_data, dict) and 'answer_criteria' in criteria_data:
                    # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    return criteria_data['answer_criteria']
                elif isinstance(criteria_data, list):
                    # ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    return criteria_data
                else:
                    print("âš ï¸ í‰ê°€ ê¸°ì¤€ í˜•ì‹ ì˜¤ë¥˜. ê¸°ë³¸ ê¸°ì¤€ ì‚¬ìš©.")
            except Exception as e:
                print(f"âš ï¸ í‰ê°€ ê¸°ì¤€ ë¡œë“œ ì˜¤ë¥˜: {e}. ê¸°ë³¸ ê¸°ì¤€ ì‚¬ìš©.")
        
        # ê¸°ë³¸ í‰ê°€ ê¸°ì¤€
        return [
            {
                'key': 'source_accuracy',
                'name': 'ì°¸ê³ ìë£Œ ì •í™•ì„±',
                'description': 'ì°¸ê³ ìë£Œë¥¼ ì •í™•íˆ ì¸ìš©í–ˆëŠ”ê°€'
            },
            {
                'key': 'source_citation',
                'name': 'ì¶œì²˜ í‘œì‹œ',
                'description': 'ëª¨ë“  ì •ë³´ì— ì¶œì²˜ê°€ í‘œì‹œë˜ì—ˆëŠ”ê°€'
            },
            {
                'key': 'no_hallucination',
                'name': 'í™˜ê° ì—†ìŒ',
                'description': 'ì°¸ê³ ìë£Œì— ì—†ëŠ” ë‚´ìš©ì„ ìƒì„±í•˜ì§€ ì•Šì•˜ëŠ”ê°€'
            },
            {
                'key': 'clarity',
                'name': 'ëª…í™•ì„±',
                'description': 'ë‹µë³€ì´ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ê°€'
            },
            {
                'key': 'completeness',
                'name': 'ì™„ì „ì„±',
                'description': 'ì§ˆë¬¸ì— ì¶©ë¶„íˆ ë‹µë³€í–ˆëŠ”ê°€'
            }
        ]
    
    def evaluate_answer(self, question: str, answer: str, sources: List[Dict]) -> Dict:
        """ì ìˆ˜ë³„ ì „ëµì„ ê³ ë ¤í•œ ë‹µë³€ í‰ê°€ (ì›ë³¸ ë°©ì‹ ìœ ì§€)"""
        
        print(f"\nğŸ“‹ ë‹µë³€ í‰ê°€: {question}")
        print(f"\nğŸ’¡ í˜„ì¬ ë‹µë³€:\n{answer}")
        
        # ì ìˆ˜ë³„ ì „ëµ ì•ˆë‚´
        print(f"\nğŸ“Š ì ìˆ˜ë³„ ì—…ë°ì´íŠ¸ ì „ëµ:")
        print(f"  ğŸ”´ 0-3ì : ì—…ë°ì´íŠ¸ ì•ˆí•¨")
        print(f"  ğŸŸ¡ 4-5ì : ì™„ì „ êµì²´ (ìƒˆë¡œ ì‘ì„± í•„ìš”)")  
        print(f"  ğŸŸ¢ 6-7ì : ë¯¸ì„¸ ì¡°ì • (ì›ë³¸ + ìˆ˜ì •ì‚¬í•­)")
        print(f"  ğŸ”µ 8-10ì : ì„ íƒì  ê°œì„  (ì›ë³¸ ìœ ì§€ + ì•½ê°„ ë³´ì™„)")
        
        # ê°„í¸ í‰ê°€
        print(f"\nâš¡ ë¹ ë¥¸ í‰ê°€:")
        print(f"1. ì™„ì „íˆ í‹€ë¦¼ (1-3ì ) - ì—…ë°ì´íŠ¸ ì•ˆí•¨")
        print(f"2. ë§ì´ í‹€ë¦¼ (4-5ì ) - ìƒˆë¡œ ì‘ì„±")
        print(f"3. ê´œì°®ì§€ë§Œ ì•„ì‰¬ì›€ (6-7ì ) - ë¯¸ì„¸ ì¡°ì •")  
        print(f"4. ê±°ì˜ ì™„ë²½ (8-10ì ) - ì•½ê°„ë§Œ ë³´ì™„")
        
        choice = input("ì„ íƒ (1-4): ").strip()
        
        if choice == '1':
            # ì—…ë°ì´íŠ¸ ì•ˆí•¨
            scores = {criterion['key']: 2 for criterion in self.criteria}
            feedback = "ë‹µë³€ì´ ë¶€ì ì ˆí•˜ì—¬ ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŒ"
            correction = ""
            
        elif choice == '2':
            # ì™„ì „ êµì²´
            scores = {criterion['key']: 4 for criterion in self.criteria}
            feedback = input("ì–´ë–¤ ì ì´ ë¬¸ì œì¸ê°€ìš”? ")
            print("ğŸ’¡ ì™„ì „íˆ ìƒˆë¡œìš´ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:")
            correction = input("ìƒˆë¡œìš´ ë‹µë³€: ")
            
        elif choice == '3':
            # ë¯¸ì„¸ ì¡°ì • - ê°€ì¥ ë§ì´ ì‚¬ìš©ë  ì¼€ì´ìŠ¤
            scores = {criterion['key']: 6 for criterion in self.criteria}
            feedback = input("ì–´ë–¤ ë¶€ë¶„ì„ ê°œì„ í•˜ë©´ ì¢‹ì„ê¹Œìš”? ")
            print("ğŸ’¡ ì¶”ê°€í•˜ê±°ë‚˜ ìˆ˜ì •í•  ë‚´ìš©ë§Œ ì…ë ¥í•´ì£¼ì„¸ìš”:")
            correction = input("ë¯¸ì„¸ ì¡°ì • ë‚´ìš©: ")
            
        elif choice == '4':
            # ì„ íƒì  ê°œì„ 
            scores = {criterion['key']: 8 for criterion in self.criteria}
            feedback = input("ë” ì¢‹ê²Œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ì ì´ ìˆë‹¤ë©´? ")
            correction = input("ì•½ê°„ì˜ ë³´ì™„ ë‚´ìš© (ì„ íƒì‚¬í•­): ")
            
        else:
            # ìˆ˜ë™ ì…ë ¥
            print("\nìƒì„¸ í‰ê°€ ëª¨ë“œ:")
            scores = {}
            for criterion in self.criteria:
                while True:
                    try:
                        score = int(input(f"{criterion['name']} (0-10): "))
                        if 0 <= score <= 10:
                            scores[criterion['key']] = score
                            break
                    except ValueError:
                        print("ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
            avg_score = sum(scores.values()) / len(scores)
            print(f"\ní˜„ì¬ í‰ê·  ì ìˆ˜: {avg_score:.1f}")
            
            if avg_score >= 8:
                print("ğŸ’¡ ë†’ì€ ì ìˆ˜ì…ë‹ˆë‹¤. ì•½ê°„ì˜ ë³´ì™„ë§Œ ì…ë ¥í•˜ì„¸ìš”.")
            elif avg_score >= 6:
                print("ğŸ’¡ ì¤‘ê°„ ì ìˆ˜ì…ë‹ˆë‹¤. ë¯¸ì„¸ ì¡°ì • ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                print("ğŸ’¡ ë‚®ì€ ì ìˆ˜ì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ë‹µë³€ì´ë‚˜ ëŒ€í­ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                
            feedback = input("í”¼ë“œë°±: ")
            correction = input("ìˆ˜ì •/ë³´ì™„ ë‚´ìš©: ")
        
        avg_score = sum(scores.values()) / len(scores)
        
        return {
            'question': question,
            'answer': answer,
            'sources': sources,
            'scores': scores,
            'avg_score': avg_score,
            'feedback': feedback,
            'correction': correction,
            'timestamp': datetime.now().isoformat(),
            'session': self.current_session
        }
        
    def save_evaluation(self, evaluation: Dict):
        """
        í‰ê°€ ë°ì´í„° ì €ì¥ (ì„¸ì…˜ë³„ + í†µí•©)
        
        :param evaluation: í‰ê°€ ë°ì´í„°
        """
        # íƒ€ì„ìŠ¤íƒ¬í”„ ë° ì„¸ì…˜ ì •ë³´ ì¶”ê°€
        evaluation['timestamp'] = datetime.now().isoformat()
        evaluation['session'] = self.current_session
        
        # ì„¸ì…˜ ìºì‹œì— ì¶”ê°€
        self.current_session_evaluations.append(evaluation)
        
        # 1. ì„¸ì…˜ë³„ í‰ê°€ íŒŒì¼ì— ì €ì¥
        session_evaluations_file = os.path.join(self.evaluations_path, "session_evaluations.json")
        
        existing_evaluations = []
        if os.path.exists(session_evaluations_file):
            try:
                with open(session_evaluations_file, 'r', encoding='utf-8') as f:
                    existing_evaluations = json.load(f)
            except json.JSONDecodeError:
                print(f"âš ï¸ ì„¸ì…˜ í‰ê°€ íŒŒì¼ ì†ìƒ. ìƒˆ íŒŒì¼ ìƒì„±í•©ë‹ˆë‹¤.")
        
        existing_evaluations.append(evaluation)
        
        with open(session_evaluations_file, 'w', encoding='utf-8') as f:
            json.dump(existing_evaluations, f, ensure_ascii=False, indent=2)
        
        # 2. í†µí•© íŒŒì¼ì—ë„ ì €ì¥
        self._save_to_aggregated(evaluation)
        
        print(f"âœ… í‰ê°€ ë°ì´í„° ì €ì¥ ì™„ë£Œ (ì„¸ì…˜: {self.current_session})")
        
        # 3. correctionì´ ìˆìœ¼ë©´ ë³„ë„ ì²˜ë¦¬
        if evaluation.get('avg_score', 0) >= 4 and evaluation.get('correction'):
            self._handle_correction(evaluation)
    
    def _save_to_aggregated(self, evaluation: Dict):
        """í†µí•© íŒŒì¼ì— í‰ê°€ ì €ì¥"""
        aggregated_file = os.path.join(self.aggregated_path, 'all_evaluations.json')
        
        existing_evaluations = []
        if os.path.exists(aggregated_file):
            try:
                with open(aggregated_file, 'r', encoding='utf-8') as f:
                    existing_evaluations = json.load(f)
            except json.JSONDecodeError:
                print(f"âš ï¸ í†µí•© í‰ê°€ íŒŒì¼ ì†ìƒ. ìƒˆ íŒŒì¼ ìƒì„±í•©ë‹ˆë‹¤.")
        
        existing_evaluations.append(evaluation)
        
        with open(aggregated_file, 'w', encoding='utf-8') as f:
            json.dump(existing_evaluations, f, ensure_ascii=False, indent=2)
    
    def _handle_correction(self, evaluation: Dict):
        """correction ì²˜ë¦¬ (ì„¸ì…˜ë³„ + í†µí•©) - ì›ë³¸ ë¡œì§ ìœ ì§€"""
        if not evaluation.get('correction'):
            return
            
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        correction_data = {
            'question': evaluation['question'],
            'original_response': evaluation['answer'],
            'corrected_response': evaluation['correction'],
            'scores': evaluation['scores'],
            'feedback': evaluation['feedback'],
            'avg_score': evaluation['avg_score'],
            'timestamp': evaluation['timestamp'],
            'session': self.current_session
        }
        
        # 1. ì„¸ì…˜ë³„ correction ì €ì¥ (ê°œë³„ íŒŒì¼)
        session_correction_file = os.path.join(self.corrections_path, f"correction_{timestamp}.json")
        with open(session_correction_file, 'w', encoding='utf-8') as f:
            json.dump(correction_data, f, ensure_ascii=False, indent=2)
        
        # 2. í†µí•© correctionsì—ë„ ì €ì¥
        aggregated_corrections_file = os.path.join(self.aggregated_path, 'all_corrections.json')
        
        existing_corrections = []
        if os.path.exists(aggregated_corrections_file):
            try:
                with open(aggregated_corrections_file, 'r', encoding='utf-8') as f:
                    existing_corrections = json.load(f)
            except json.JSONDecodeError:
                print("âš ï¸ all_corrections.json íŒŒì¼ ì†ìƒ. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        
        existing_corrections.append(correction_data)
        
        with open(aggregated_corrections_file, 'w', encoding='utf-8') as f:
            json.dump(existing_corrections, f, ensure_ascii=False, indent=2)
    
    def save_session(self):
        """í˜„ì¬ ì„¸ì…˜ ìš”ì•½ ì €ì¥"""
        if not self.current_session_evaluations:
            print("ì €ì¥í•  ì„¸ì…˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì„¸ì…˜ ìš”ì•½ ìƒì„±
        session_summary = {
            'session_id': self.current_session,
            'session_date': datetime.now().isoformat(),
            'total_evaluations': len(self.current_session_evaluations),
            'avg_score': sum(e.get('avg_score', 0) for e in self.current_session_evaluations) / len(self.current_session_evaluations),
            'score_distribution': self._calculate_score_distribution(),
            'corrections_count': len([e for e in self.current_session_evaluations if e.get('correction')]),
            'evaluations': self.current_session_evaluations
        }
        
        # ì„¸ì…˜ ìš”ì•½ ì €ì¥
        summary_file = os.path.join(self.session_dir, 'session_summary.json')
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(session_summary, f, ensure_ascii=False, indent=2)
        
        # í†µí•© ì„¸ì…˜ ìš”ì•½ì—ë„ ì €ì¥
        summaries_file = os.path.join(self.aggregated_path, "session_summaries.json")
        
        existing_summaries = []
        if os.path.exists(summaries_file):
            try:
                with open(summaries_file, 'r', encoding='utf-8') as f:
                    existing_summaries = json.load(f)
            except json.JSONDecodeError:
                print(f"âš ï¸ ì†ìƒëœ ì„¸ì…˜ ìš”ì•½ íŒŒì¼ ë°œê²¬. ìƒˆ íŒŒì¼ ìƒì„±í•©ë‹ˆë‹¤.")
        
        existing_summaries.append(session_summary)
        
        with open(summaries_file, 'w', encoding='utf-8') as f:
            json.dump(existing_summaries, f, ensure_ascii=False, indent=2)
        
        # ì„¸ì…˜ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
        self._update_session_index(session_summary)
        
        print(f"âœ… ì„¸ì…˜ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {self.current_session}")
        print(f"   - ì´ í‰ê°€: {session_summary['total_evaluations']}ê°œ")
        print(f"   - í‰ê·  ì ìˆ˜: {session_summary['avg_score']:.1f}/10")
        print(f"   - Corrections: {session_summary['corrections_count']}ê°œ")
    
    def _calculate_score_distribution(self) -> Dict:
        """ì ìˆ˜ ë¶„í¬ ê³„ì‚°"""
        scores = [e.get('avg_score', 0) for e in self.current_session_evaluations]
        
        return {
            'excellent': len([s for s in scores if s >= 8]),
            'good': len([s for s in scores if 6 <= s < 8]),
            'poor': len([s for s in scores if 4 <= s < 6]),
            'very_poor': len([s for s in scores if s < 4])
        }
    
    def _update_session_index(self, session_summary: Dict):
        """ì„¸ì…˜ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸"""
        index_file = os.path.join(self.aggregated_path, 'session_index.json')
        
        existing_index = []
        if os.path.exists(index_file):
            try:
                with open(index_file, 'r', encoding='utf-8') as f:
                    existing_index = json.load(f)
            except json.JSONDecodeError:
                existing_index = []
        
        # ê¸°ì¡´ ì„¸ì…˜ ì •ë³´ ì—…ë°ì´íŠ¸ ë˜ëŠ” ìƒˆë¡œ ì¶”ê°€
        session_info = {
            'session_id': session_summary['session_id'],
            'date': session_summary['session_date'],
            'total_evaluations': session_summary['total_evaluations'],
            'avg_score': session_summary['avg_score'],
            'corrections_count': session_summary['corrections_count']
        }
        
        # ê¸°ì¡´ ì„¸ì…˜ ì°¾ì•„ì„œ ì—…ë°ì´íŠ¸
        updated = False
        for i, existing_session in enumerate(existing_index):
            if existing_session['session_id'] == session_summary['session_id']:
                existing_index[i] = session_info
                updated = True
                break
        
        if not updated:
            existing_index.append(session_info)
        
        with open(index_file, 'w', encoding='utf-8') as f:
            json.dump(existing_index, f, ensure_ascii=False, indent=2)
    
    def get_low_score_evaluations(self, threshold: float = 7.0) -> List[Dict]:
        """
        ë‚®ì€ ì ìˆ˜ì˜ í‰ê°€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        
        :param threshold: ì ìˆ˜ ì„ê³„ê°’
        :return: ë‚®ì€ ì ìˆ˜ì˜ í‰ê°€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        low_score_evals = []
        
        # í†µí•© í‰ê°€ ë°ì´í„° ë¡œë“œ
        evaluations_file = os.path.join(self.aggregated_path, "all_evaluations.json")
        if os.path.exists(evaluations_file):
            try:
                with open(evaluations_file, 'r', encoding='utf-8') as f:
                    all_evaluations = json.load(f)
                    
                # ë‚®ì€ ì ìˆ˜ í•„í„°ë§
                low_score_evals = [
                    e for e in all_evaluations 
                    if e.get('avg_score', 0) < threshold
                ]
            except Exception as e:
                print(f"í‰ê°€ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        
        return low_score_evals
    
    def get_all_corrections(self) -> List[Dict]:
        """
        ëª¨ë“  ìˆ˜ì • ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (í†µí•© íŒŒì¼ì—ì„œ)
        
        :return: ëª¨ë“  ìˆ˜ì • ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        corrections = []
        
        # í†µí•© corrections íŒŒì¼ì—ì„œ ë¡œë“œ
        all_corrections_file = os.path.join(self.aggregated_path, 'all_corrections.json')
        if os.path.exists(all_corrections_file):
            try:
                with open(all_corrections_file, 'r', encoding='utf-8') as f:
                    corrections = json.load(f)
            except Exception as e:
                print(f"í†µí•© ìˆ˜ì • ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        
        return corrections
    
    def get_all_sessions(self) -> List[str]:
        """ëª¨ë“  ì„¸ì…˜ ëª©ë¡ ë°˜í™˜"""
        if not os.path.exists(self.sessions_path):
            return []
        
        sessions = [d for d in os.listdir(self.sessions_path) 
                   if d.startswith('session_') and os.path.isdir(os.path.join(self.sessions_path, d))]
        
        return sorted(sessions)
    
    def show_session_stats(self):
        """ì„¸ì…˜ í†µê³„ í‘œì‹œ"""
        sessions = self.get_all_sessions()
        
        if not sessions:
            print("ğŸ“Š ì„¸ì…˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nğŸ“Š ì„¸ì…˜ í†µê³„ (ì´ {len(sessions)}ê°œ ì„¸ì…˜):")
        
        index_file = os.path.join(self.aggregated_path, 'session_index.json')
        if os.path.exists(index_file):
            try:
                with open(index_file, 'r', encoding='utf-8') as f:
                    session_index = json.load(f)
                
                for session in session_index:
                    print(f"  ğŸ“ {session['session_id']}")
                    print(f"     í‰ê°€: {session['total_evaluations']}ê°œ, í‰ê· : {session['avg_score']:.1f}/10, ìˆ˜ì •: {session['corrections_count']}ê°œ")
                    
            except Exception as e:
                print(f"ì„¸ì…˜ ì¸ë±ìŠ¤ ë¡œë“œ ì˜¤ë¥˜: {e}")
    
    def generate_improvement_report(self, output_path: Optional[str] = None) -> Dict:
        """
        ê°œì„  ë¦¬í¬íŠ¸ ìƒì„±
        
        :param output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ì—†ìœ¼ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ)
        :return: ë¦¬í¬íŠ¸ ë°ì´í„°
        """
        # ëª¨ë“  í‰ê°€ ë°ì´í„° ë¡œë“œ (í†µí•© íŒŒì¼ì—ì„œ)
        all_evaluations = []
        evaluations_file = os.path.join(self.aggregated_path, "all_evaluations.json")
        if os.path.exists(evaluations_file):
            try:
                with open(evaluations_file, 'r', encoding='utf-8') as f:
                    all_evaluations = json.load(f)
            except Exception as e:
                print(f"í‰ê°€ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        
        # ëª¨ë“  ìˆ˜ì • ë°ì´í„° ë¡œë“œ
        all_corrections = self.get_all_corrections()
        
        # í†µê³„ ê³„ì‚°
        total_evals = len(all_evaluations)
        avg_score = sum(e.get('avg_score', 0) for e in all_evaluations) / total_evals if total_evals > 0 else 0
        low_score_count = len([e for e in all_evaluations if e.get('avg_score', 0) < 7])
        
        # ê¸°ì¤€ë³„ í‰ê·  ì ìˆ˜
        criteria_scores = {}
        for evaluation in all_evaluations:
            scores = evaluation.get('scores', {})
            for key, score in scores.items():
                if key not in criteria_scores:
                    criteria_scores[key] = []
                criteria_scores[key].append(score)
        
        criteria_avgs = {
            key: sum(scores) / len(scores) if scores else 0 
            for key, scores in criteria_scores.items()
        }
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report = {
            'timestamp': datetime.now().isoformat(),
            'statistics': {
                'total_evaluations': total_evals,
                'average_score': avg_score,
                'low_score_count': low_score_count,
                'correction_count': len(all_corrections),
                'total_sessions': len(self.get_all_sessions())
            },
            'criteria_averages': criteria_avgs,
            'improvement_areas': [
                {
                    'criterion': key,
                    'average_score': avg,
                    'priority': 'high' if avg < 6 else ('medium' if avg < 7.5 else 'low')
                }
                for key, avg in sorted(criteria_avgs.items(), key=lambda x: x[1])
            ]
        }
        
        # ì €ì¥
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“Š ê°œì„  ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {output_path}")
        
        return report

def main():
    """í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜"""
    evaluator = FineTuningEvaluator()
    
    # í‰ê°€ ê¸°ì¤€ ì¶œë ¥
    print("ğŸ“‹ í‰ê°€ ê¸°ì¤€:")
    for criterion in evaluator.criteria:
        print(f"- {criterion.get('name')}: {criterion.get('description')}")
    
    # ì„¸ì…˜ í†µê³„ í‘œì‹œ
    evaluator.show_session_stats()
    
    # ê°œì„  ë¦¬í¬íŠ¸ ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = os.path.join(evaluator.aggregated_path, f"improvement_report_{timestamp}.json")
    report = evaluator.generate_improvement_report(report_path)
    
    print("\nğŸ“Š ê°œì„  ë¦¬í¬íŠ¸ ìš”ì•½:")
    print(f"ì´ í‰ê°€: {report['statistics']['total_evaluations']}ê°œ")
    print(f"í‰ê·  ì ìˆ˜: {report['statistics']['average_score']:.2f}/10")
    print(f"ê°œì„  í•„ìš”: {report['statistics']['low_score_count']}ê°œ")
    print(f"ì´ ì„¸ì…˜: {report['statistics']['total_sessions']}ê°œ")

if __name__ == "__main__":
    main()
import json
import os
import re
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import shutil

class ModelUpdater:
    def __init__(self, base_path='data/fine_tuning', raw_data_path='data/raw/music_theory_curriculum.json'):
        """
        ëª¨ë¸ ì—…ë°ì´íŠ¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        :param base_path: íŒŒì¸íŠœë‹ ë°ì´í„° ê²½ë¡œ
        :param raw_data_path: ì›ë³¸ JSON ë°ì´í„° ê²½ë¡œ
        """
        self.base_path = base_path
        self.corrections_path = os.path.join(base_path, 'corrections')
        self.keywords_path = os.path.join(base_path, 'keywords')
        self.raw_data_path = raw_data_path
        
        # ì›ë³¸ ë°ì´í„° ë¡œë“œ
        self.raw_data = self._load_raw_data()
        
        # íŒŒì¸íŠœë‹ í‚¤ì›Œë“œ ë¡œë“œ
        self.fine_tuning_keywords = self._load_fine_tuning_keywords()
        
        # ì—…ë°ì´íŠ¸ ì´ë ¥
        self.update_history = []
    
    def _load_raw_data(self) -> Dict:
        """ì›ë³¸ JSON ë°ì´í„° ë¡œë“œ"""
        try:
            with open(self.raw_data_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError) as e:
            print(f"ì›ë³¸ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            return {}
    
    def _load_fine_tuning_keywords(self) -> List[str]:
        """íŒŒì¸íŠœë‹ í‚¤ì›Œë“œ ë¡œë“œ"""
        keywords_file = os.path.join(self.keywords_path, 'extracted_keywords.json')
        try:
            with open(keywords_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"í‚¤ì›Œë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {keywords_file}")
            return []
    
    def _save_raw_data(self):
        """ìˆ˜ì •ëœ ë°ì´í„° ì €ì¥"""
        # ë°±ì—… ìƒì„±
        self._create_backup()
        
        # ì €ì¥
        try:
            with open(self.raw_data_path, 'w', encoding='utf-8') as f:
                json.dump(self.raw_data, f, ensure_ascii=False, indent=2)
            print(f"âœ… ì›ë³¸ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ: {self.raw_data_path}")
        except Exception as e:
            print(f"ë°ì´í„° ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def _create_backup(self):
        """ì›ë³¸ ë°ì´í„° ë°±ì—… ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = "data/raw/backups"
        os.makedirs(backup_dir, exist_ok=True)
        
        backup_path = os.path.join(backup_dir, f"music_theory_curriculum_{timestamp}.json")
        shutil.copy2(self.raw_data_path, backup_path)
        print(f"ğŸ“ ì›ë³¸ ë°ì´í„° ë°±ì—… ìƒì„±: {backup_path}")
    
    def load_corrections(self) -> List[Dict]:
        """ëª¨ë“  ìˆ˜ì • ë°ì´í„° ë¡œë“œ"""
        corrections = []
        
        if not os.path.exists(self.corrections_path):
            return corrections
        
        for filename in os.listdir(self.corrections_path):
            if filename.startswith('correction_'):
                filepath = os.path.join(self.corrections_path, filename)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        corrections.append(json.load(f))
                except Exception as e:
                    print(f"ìˆ˜ì • ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜ ({filename}): {e}")
        
        return sorted(corrections, key=lambda x: x.get('timestamp', ''))
    
    def _extract_keywords(self, text: str) -> List[str]:
        """
        íŒŒì¸íŠœë‹ í‚¤ì›Œë“œì™€ ì…ë ¥ í…ìŠ¤íŠ¸ ë§¤ì¹­
        
        :param text: ì…ë ¥ í…ìŠ¤íŠ¸
        :return: ë§¤ì¹­ëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        """
        text_lower = text.lower()
        matched_keywords = []
        
        for keyword in self.fine_tuning_keywords:
            if keyword.lower() in text_lower:
                matched_keywords.append(keyword)
        
        return sorted(matched_keywords, key=len, reverse=True)
    
    def find_update_location(self, question: str, response: str) -> Tuple[Dict, str, Optional[str]]:
        """
        ì›ë³¸ ë°ì´í„°ì—ì„œ ì—…ë°ì´íŠ¸ ìœ„ì¹˜ ì°¾ê¸°
        
        :param question: ì§ˆë¬¸
        :param response: ì‘ë‹µ
        :return: (ì—…ë°ì´íŠ¸ ìœ„ì¹˜, í‚¤ì›Œë“œ, ì„¹ì…˜ ì´ë¦„)
        """
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords(question)
        
        # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ í‚¤ì›Œë“œ ì„ íƒ
        main_keyword = keywords[0] if keywords else ""
        
        # í‚¤ì›Œë“œë¡œ ê´€ë ¨ ì„¹ì…˜ ì°¾ê¸°
        target_section, section_name = self._find_related_section(main_keyword)
        
        return target_section, main_keyword, section_name
    
    def _find_related_section(self, keyword: str) -> Tuple[Dict, Optional[str]]:
        """í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ì„¹ì…˜ ì°¾ê¸°"""
        def search_recursively(obj, path=""):
            if isinstance(obj, dict):
                # ì œëª©ì´ë‚˜ ì„¤ëª…ì— í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
                for k in ['title', 'description', 'name', 'definition']:
                    if k in obj and isinstance(obj[k], str) and keyword.lower() in obj[k].lower():
                        return obj, path
                
                # ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰
                for k, v in obj.items():
                    result, found_path = search_recursively(v, f"{path}.{k}" if path else k)
                    if result is not None:
                        return result, found_path
                        
            elif isinstance(obj, list):
                for i, item in enumerate(obj):
                    result, found_path = search_recursively(item, f"{path}[{i}]")
                    if result is not None:
                        return result, found_path
            
            return None, None
        
        # í‚¤ì›Œë“œê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°
        if not keyword:
            return self.raw_data, None
        
        # í‚¤ì›Œë“œë¡œ ê´€ë ¨ ì„¹ì…˜ ì°¾ê¸°
        section, path = search_recursively(self.raw_data)
        
        # ê´€ë ¨ ì„¹ì…˜ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ìµœìƒìœ„ ë°ì´í„° ë°˜í™˜
        if section is None:
            return self.raw_data, None
        
        return section, path
    
    def update_model_data(self, correction: Dict):
        """ëª¨ë¸ ë°ì´í„° ì—…ë°ì´íŠ¸"""
        question = correction.get('question', '')
        original_response = correction.get('original_response', '')
        corrected_response = correction.get('corrected_response', '')
        
        if not corrected_response:
            print("ìˆ˜ì •ëœ ì‘ë‹µì´ ì—†ì–´ ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return
        
        # ì—…ë°ì´íŠ¸ ìœ„ì¹˜ ì°¾ê¸°
        target_section, keyword, section_name = self.find_update_location(question, original_response)
        
        # ì—…ë°ì´íŠ¸ ì‘ì—…
        update_success = False
        
        # 1. ê¸°ì¡´ í•„ë“œ ì—…ë°ì´íŠ¸
        if isinstance(target_section, dict):
            for field in ['description', 'detailed_explanation', 'explanation', 'definition']:
                if field in target_section and isinstance(target_section[field], str):
                    # í•„ë“œ ë‚´ìš©ì´ ì›ë³¸ ì‘ë‹µê³¼ ìœ ì‚¬í•œì§€ í™•ì¸
                    similarity = self._calculate_text_similarity(target_section[field], original_response)
                    if similarity > 0.3:  # ìœ ì‚¬ë„ ì„ê³„ê°’
                        print(f"'{field}' í•„ë“œ ì—…ë°ì´íŠ¸ (ìœ ì‚¬ë„: {similarity:.2f})")
                        target_section[field] = corrected_response
                        update_success = True
                        break
        
        # 2. ê´€ë ¨ ì„¹ì…˜ì— ìƒˆ í•„ë“œ ì¶”ê°€
        if not update_success and keyword and isinstance(target_section, dict):
            if 'explanation' not in target_section:
                field_name = 'explanation'
            elif 'additional_info' not in target_section:
                field_name = 'additional_info'
            else:
                field_name = f'info_about_{keyword.lower()}'
            
            print(f"ìƒˆ í•„ë“œ '{field_name}' ì¶”ê°€")
            target_section[field_name] = corrected_response
            update_success = True
        
        # 3. ìµœìƒìœ„ ë ˆë²¨ì— ìƒˆ ì„¹ì…˜ ì¶”ê°€
        if not update_success:
            if 'concept_corrections' not in self.raw_data:
                self.raw_data['concept_corrections'] = {}
            
            section_key = keyword.lower() if keyword else f"topic_{len(self.raw_data['concept_corrections']) + 1}"
            
            print(f"'concept_corrections' ì„¹ì…˜ì— '{section_key}' ì¶”ê°€")
            self.raw_data['concept_corrections'][section_key] = {
                'question': question,
                'correct_explanation': corrected_response,
                'keyword': keyword
            }
            update_success = True
        
        # ì—…ë°ì´íŠ¸ ì´ë ¥ ì¶”ê°€
        if update_success:
            self.update_history.append({
                'timestamp': datetime.now().isoformat(),
                'question': question,
                'section': section_name,
                'keyword': keyword
            })
    
    def _calculate_text_similarity(self, text1: str, text2: str) -> float:
        """ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê³„ì‚°"""
        words1 = set(re.findall(r'\b[\wê°€-í£]+\b', text1.lower()))
        words2 = set(re.findall(r'\b[\wê°€-í£]+\b', text2.lower()))
        
        if not words1 or not words2:
            return 0
        
        common_words = words1.intersection(words2)
        return len(common_words) / max(len(words1), len(words2))
    
    def regenerate_embeddings(self):
        """ì„ë² ë”© ì¬ìƒì„±"""
        try:
            import sys
            import os
            sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
            
            from src.data_processing.json_loader import MusicTheoryDataLoader
            from src.data_processing.embedding_generator import EmbeddingGenerator
            
            # ë°ì´í„° ë¡œë“œ
            loader = MusicTheoryDataLoader()
            data = loader.load_data()
            chunks = loader.extract_text_chunks()
            
            # ì„ë² ë”© ìƒì„±
            embedder = EmbeddingGenerator()
            embeddings = embedder.generate_embeddings(chunks)
            embedder.save_embeddings()
            
            print("âœ… ì„ë² ë”© ì¬ìƒì„± ì™„ë£Œ")
            return True
        except Exception as e:
            print(f"ì„ë² ë”© ì¬ìƒì„± ì˜¤ë¥˜: {e}")
            return False
    
    def process_all_corrections(self):
        """ëª¨ë“  ìˆ˜ì • ë°ì´í„° ì²˜ë¦¬ ë° ëª¨ë¸ ì—…ë°ì´íŠ¸"""
        # ìˆ˜ì • ë°ì´í„° ë¡œë“œ
        corrections = self.load_corrections()
        
        if not corrections:
            print("ì²˜ë¦¬í•  ìˆ˜ì • ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ì´ {len(corrections)}ê°œì˜ ìˆ˜ì • ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        
        # ê° ìˆ˜ì • ì ìš©
        for idx, correction in enumerate(corrections, 1):
            print(f"\nì²˜ë¦¬ ì¤‘ {idx}/{len(corrections)}: {correction.get('question', '')[:50]}...")
            self.update_model_data(correction)
        
        # ë°ì´í„° ì €ì¥
        self._save_raw_data()
        
        # ì„ë² ë”© ì¬ìƒì„±
        self.regenerate_embeddings()
        
        print(f"\nâœ… ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ! ì´ {len(self.update_history)}ê°œì˜ ë³€ê²½ì‚¬í•­ ì ìš©")

def main():
    updater = ModelUpdater()
    updater.process_all_corrections()

if __name__ == "__main__":
    main()
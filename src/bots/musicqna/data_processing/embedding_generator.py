import numpy as np
from sentence_transformers import SentenceTransformer
from typing import List, Dict, Tuple
import pickle
import os
import torch

class EmbeddingGenerator:
    def __init__(
        self, 
        model_name: str = None, 
        embedding_path: str = 'data/musicqna/embeddings/music_theory_embeddings.pkl'
    ):
        if model_name is None:
            model_name = "intfloat/multilingual-e5-large"
        print(f"ğŸµ ì„ë² ë”© ëª¨ë¸ ë¡œë”©: {model_name}")

        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ğŸ–¥ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")

        self.model = SentenceTransformer(model_name, device=self.device)
        self.model_name = model_name
        self.embedding_path = embedding_path
        self.embeddings = None
        self.chunks = None

    def generate_embeddings(self, text_chunks: List[Dict]) -> np.ndarray:
        texts = []
        for chunk in text_chunks:
            # ìš©ì–´ ê°•ì¡° + ì£¼ìš” í•„ë“œ ì¡°í•© (íƒœê·¸ ë¶€ì—¬ë¡œ weighting íš¨ê³¼)
            parts = [
                f"[KEYWORD] {chunk.get('concept.ko', '')}",
                f"[KEYWORD_EN] {chunk.get('concept.en', '')}",
                f"[ALIAS] {chunk.get('aliases', '')}",
                f"[DEF] {chunk.get('definition', '')}",
                f"[LOGIC] {chunk.get('logic', '')}",
                f"[EX_NAME] {chunk.get('examples.name', '')}",
                f"[EX_DESC] {chunk.get('examples.description', '')}",
                f"[TIPS] {chunk.get('tips', '')}",
                f"[PREQ_KO] {chunk.get('prerequisites.ko', '')}",
                f"[PREQ_EN] {chunk.get('prerequisites.en', '')}"
            ]
            combined_text = ' '.join([part for part in parts if part and part != ''])
            texts.append(combined_text)
        
        print(f"ğŸµ {len(texts)}ê°œì˜ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„ë² ë”© ìƒì„± ì¤‘...")
        embeddings = self.model.encode(
            texts,
            batch_size=32,
            show_progress_bar=True,
            normalize_embeddings=True,
            convert_to_numpy=True
        )
        self.embeddings = embeddings
        self.chunks = text_chunks
        print(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ: shape {embeddings.shape}")
        return embeddings

    def save_embeddings(self):
        os.makedirs(os.path.dirname(self.embedding_path), exist_ok=True)
        embedding_data = {
            'embeddings': self.embeddings.tolist(),
            'chunks': self.chunks,
            'model_name': self.model_name
        }
        with open(self.embedding_path, 'wb') as f:
            pickle.dump(embedding_data, f)
        print(f"âœ… ì„ë² ë”© ì €ì¥ ì™„ë£Œ: {len(self.chunks)}ê°œ, {self.embedding_path}")

    def load_embeddings(self) -> bool:
        try:
            with open(self.embedding_path, 'rb') as f:
                embedding_data = pickle.load(f)
            self.embeddings = np.array(embedding_data['embeddings'])
            self.chunks = embedding_data['chunks']
            self.model_name = embedding_data.get('model_name', 'unknown')
            print(f"âœ… ì„ë² ë”© ë¡œë“œ ì™„ë£Œ: {len(self.chunks)}ê°œ, ëª¨ë¸: {self.model_name}")
            return True
        except FileNotFoundError:
            print(f"âŒ ì„ë² ë”© íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.embedding_path}")
            return False
        except Exception as e:
            print(f"âŒ ì„ë² ë”© ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def get_embeddings(self) -> Tuple[np.ndarray, List[Dict]]:
        if self.embeddings is None or self.chunks is None:
            raise ValueError("ì„ë² ë”©ì´ ìƒì„±ë˜ê±°ë‚˜ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return self.embeddings, self.chunks

    def search_similar(self, query: str, top_k: int = 5) -> List[Dict]:
        if self.embeddings is None:
            print("âŒ ì„ë² ë”©ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        query_embedding = self.model.encode(
            query,
            normalize_embeddings=True,
            convert_to_numpy=True
        )
        similarities = np.dot(self.embeddings, query_embedding)
        top_indices = np.argsort(similarities)[::-1][:top_k]
        results = []
        for idx in top_indices:
            results.append({
                'chunk': self.chunks[idx],
                'score': float(similarities[idx])
            })
        return results

    def get_embedding_stats(self) -> Dict:
        if self.embeddings is None:
            return {"status": "No embeddings loaded"}
        stats = {
            'model_name': self.model_name,
            'num_embeddings': len(self.embeddings),
            'embedding_dim': self.embeddings.shape[1],
            'mean_norm': float(np.mean(np.linalg.norm(self.embeddings, axis=1))),
            'std_norm': float(np.std(np.linalg.norm(self.embeddings, axis=1))),
            'memory_size_mb': self.embeddings.nbytes / (1024 * 1024)
        }
        return stats

# ---- Main ì‹¤í–‰ ì˜ˆì‹œ ----

def main():
    from .json_loader import MusicTheoryDataLoader
    print("ğŸµ ìŒì•… ì´ë¡  ì„ë² ë”© ìƒì„± ì‹œì‘")

    print("\n1ï¸âƒ£ ë°ì´í„° ë¡œë”©...")
    loader = MusicTheoryDataLoader()
    loader.load_data()
    chunks = loader.extract_text_chunks()  # ìµœì‹  JSONì—ì„œ dict ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ

    print("\n2ï¸âƒ£ ì„ë² ë”© ìƒì„±...")
    embedder = EmbeddingGenerator()
    embeddings = embedder.generate_embeddings(chunks)

    print("\n3ï¸âƒ£ ì„ë² ë”© í†µê³„:")
    stats = embedder.get_embedding_stats()
    for key, value in stats.items():
        print(f"  - {key}: {value}")

    print("\n4ï¸âƒ£ ì„ë² ë”© ì €ì¥...")
    embedder.save_embeddings()

    print("\n5ï¸âƒ£ í…ŒìŠ¤íŠ¸ ê²€ìƒ‰...")
    test_query = "ì„¸ì»¨ë”ë¦¬ ë„ë¯¸ë„ŒíŠ¸"
    results = embedder.search_similar(test_query, top_k=3)
    print(f"\nì¿¼ë¦¬: '{test_query}'")
    print("ìœ ì‚¬í•œ ì²­í¬:")
    for i, result in enumerate(results, 1):
        chunk = result['chunk']
        concept = chunk.get('concept.ko') or chunk.get('concept.en') or '[No concept]'
        definition = chunk.get('definition', '')[:100]
        print(f"\n{i}. ìœ ì‚¬ë„: {result['score']:.3f}")
        print(f"   ìš©ì–´: {concept}")
        print(f"   ì •ì˜: {definition}...")
    if results:
        print("\n[1ë²ˆ chunk ì „ì²´ êµ¬ì¡° ë””ë²„ê¹…]")
        import pprint
        pprint.pprint(results[0]['chunk'])

if __name__ == "__main__":
    main()